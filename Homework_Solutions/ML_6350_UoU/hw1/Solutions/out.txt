445, 111
DT.size() = 0
DT.size() = 0
+(278)
-(167)
xxnode->totalCount = 445
+[label with max classified samples @ this node]
entropy += 0.42401
entropy += 0.954641
**********1
**********2
4-#a
#b
#c
+(202)
-(122)
xxnode->totalCount = 324
+[label with max classified samples @ this node]
entropy += 0.424972
entropy += 0.955564
+(69)
-(52)
xxnode->totalCount = 121
+[label with max classified samples @ this node]
entropy += 0.462094
entropy += 0.985714
32/////////////////////////////////////
## : 2
445@#: 0.258904
445@#: -0.00912131
5-#a
#b
#c
+(212)
-(126)
xxnode->totalCount = 338
+[label with max classified samples @ this node]
entropy += 0.422093
entropy += 0.952784
+(63)
-(44)
xxnode->totalCount = 107
+[label with max classified samples @ this node]
entropy += 0.449942
entropy += 0.977134
32/////////////////////////////////////
## : 2
445@#: 0.954641
445@#: 0.719689
6-#a
#b
#c
+(263)
-(156)
xxnode->totalCount = 419
+[label with max classified samples @ this node]
entropy += 0.421734
entropy += 0.952433
+(13)
-(13)
xxnode->totalCount = 26
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
445@#: 0.954641
445@#: 0.896214
7-#a
#b
#c
+(123)
-(82)
xxnode->totalCount = 205
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(145)
-(95)
xxnode->totalCount = 240
+[label with max classified samples @ this node]
entropy += 0.439218
entropy += 0.968461
32/////////////////////////////////////
## : 2
445@#: 0.507349
445@#: -0.0149671
8-#a
#b
#c
+(72)
-(54)
xxnode->totalCount = 126
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(199)
-(120)
xxnode->totalCount = 319
+[label with max classified samples @ this node]
entropy += 0.424692
entropy += 0.955296
32/////////////////////////////////////
## : 2
445@#: 0.954641
445@#: 0.269833
9-#a
#b
#c
+(139)
-(93)
xxnode->totalCount = 232
+[label with max classified samples @ this node]
entropy += 0.442787
entropy += 0.971453
+(130)
-(83)
xxnode->totalCount = 213
+[label with max classified samples @ this node]
entropy += 0.434763
entropy += 0.964587
32/////////////////////////////////////
## : 2
445@#: 0.954641
445@#: 0.49294

IG for each feature : 
-0.00912131, 0.719689, 0.896214, -0.0149671, 0.269833, 0.49294, 
max_IG = 0.896214 & splitOn_feature : 2
$$$$: decisionTree.size(): 1
$$$$: treeLevel_node : 0
$$$$: isLeaf_else: 0
$$$$: treeLevel_else: 1
$$$$: isLeaf_else: 0
$$$$: treeLevel_else: 1
2x----------
## : 0
0.954641  ~~~~~  0.954641
, , , 3, 0x9e1aa0, 445, 0.954641
before
DT.size() = 2
4-#a
#b
#c
+(194)
-(114)
xxnode->totalCount = 308
+[label with max classified samples @ this node]
entropy += 0.420044
entropy += 0.950772
+(67)
-(44)
xxnode->totalCount = 111
+[label with max classified samples @ this node]
entropy += 0.439621
entropy += 0.968804
32/////////////////////////////////////
## : 2
419@#: 0.253536
419@#: -0.00311561
5-#a
#b
#c
+(200)
-(122)
xxnode->totalCount = 322
+[label with max classified samples @ this node]
entropy += 0.426746
entropy += 0.957249
+(56)
-(41)
xxnode->totalCount = 97
+[label with max classified samples @ this node]
entropy += 0.457559
entropy += 0.982681
32/////////////////////////////////////
## : 2
419@#: -30.751
419@#: -30.9785
6-#a
#b
#c
+(247)
-(147)
xxnode->totalCount = 394
+[label with max classified samples @ this node]
entropy += 0.422335
entropy += 0.95302
+(12)
-(13)
xxnode->totalCount = 25
-[label with max classified samples @ this node]
entropy += 0.508269
entropy += 0.998846
32/////////////////////////////////////
## : 2
419@#: 0.0562758
419@#: -0.00332114
7-#a
#b
#c
+(113)
-(78)
xxnode->totalCount = 191
+[label with max classified samples @ this node]
entropy += 0.448006
entropy += 0.97564
+(138)
-(90)
xxnode->totalCount = 228
+[label with max classified samples @ this node]
entropy += 0.438432
entropy += 0.967788
32/////////////////////////////////////
## : 2
419@#: 0.50769
419@#: -0.0189347
8-#a
#b
#c
+(69)
-(51)
xxnode->totalCount = 120
+[label with max classified samples @ this node]
entropy += 0.459061
entropy += 0.983708
+(189)
-(110)
xxnode->totalCount = 299
+[label with max classified samples @ this node]
entropy += 0.418303
entropy += 0.949041
32/////////////////////////////////////
## : 2
419@#: 0.952433
419@#: 0.275194
9-#a
#b
#c
+(133)
-(87)
xxnode->totalCount = 220
+[label with max classified samples @ this node]
entropy += 0.438947
entropy += 0.968229
+(119)
-(80)
xxnode->totalCount = 199
+[label with max classified samples @ this node]
entropy += 0.443593
entropy += 0.972114
32/////////////////////////////////////
## : 2
419@#: 0.952433
419@#: 0.490737

IG for each feature : 
-0.00311561, -30.9785, -0.00332114, -0.0189347, 0.275194, 0.490737, 
max_IG = 0.490737 & splitOn_feature : 5
$$$$: decisionTree.size(): 2
$$$$: treeLevel_node : 1
$$$$: isLeaf_else: 0
$$$$: treeLevel_else: 2
$$$$: isLeaf_else: 0
$$$$: treeLevel_else: 2
4-#a
#b
#c
+(10)
-(9)
xxnode->totalCount = 19
+[label with max classified samples @ this node]
entropy += 0.487368
entropy += 0.998001
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
26@#: 0.270692
26@#: 0.00543793
5-#a
#b
#c
+(10)
-(9)
xxnode->totalCount = 19
+[label with max classified samples @ this node]
entropy += 0.487368
entropy += 0.998001
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
26@#: 0.270692
26@#: 0.00543793
6-#a
#b
#c
+(11)
-(13)
xxnode->totalCount = 24
-[label with max classified samples @ this node]
entropy += 0.515868
entropy += 0.994985
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
26@#: 1
26@#: 0.923077
7-#a
#b
#c
+(6)
-(5)
xxnode->totalCount = 11
+[label with max classified samples @ this node]
entropy += 0.476983
entropy += 0.99403
+(7)
-(8)
xxnode->totalCount = 15
-[label with max classified samples @ this node]
entropy += 0.513117
entropy += 0.996792
32/////////////////////////////////////
## : 2
26@#: 0.579449
26@#: 0.00437666
8-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(9)
-(9)
xxnode->totalCount = 18
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
26@#: 1
26@#: 0.307692
9-#a
#b
#c
+(7)
-(8)
xxnode->totalCount = 15
-[label with max classified samples @ this node]
entropy += 0.513117
entropy += 0.996792
+(6)
-(5)
xxnode->totalCount = 11
+[label with max classified samples @ this node]
entropy += 0.476983
entropy += 0.99403
32/////////////////////////////////////
## : 2
26@#: 0.424928
26@#: 0.00437666

IG for each feature : 
0.00543793, 0.00543793, 0.923077, 0.00437666, 0.307692, 0.00437666, 
max_IG = 0.923077 & splitOn_feature : 2
$$$$: decisionTree.size(): 3
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 2
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 2
Harry Potter*-------------------*-*-*-*--*-*--*-*
4-#a
#b
#c
+(92)
-(65)
xxnode->totalCount = 157
+[label with max classified samples @ this node]
entropy += 0.451831
entropy += 0.97856
+(35)
-(28)
xxnode->totalCount = 63
+[label with max classified samples @ this node]
entropy += 0.471109
entropy += 0.991076
32/////////////////////////////////////
## : 2
220@#: 0.269894
220@#: -0.0139143
5-#a
#b
#c
+(96)
-(65)
xxnode->totalCount = 161
+[label with max classified samples @ this node]
entropy += 0.444793
entropy += 0.973089
+(34)
-(25)
xxnode->totalCount = 59
+[label with max classified samples @ this node]
entropy += 0.458239
entropy += 0.983149
32/////////////////////////////////////
## : 2
220@#: 0.968229
220@#: 0.704567
6-#a
#b
#c
+(123)
-(82)
xxnode->totalCount = 205
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(7)
-(8)
xxnode->totalCount = 15
-[label with max classified samples @ this node]
entropy += 0.513117
entropy += 0.996792
32/////////////////////////////////////
## : 2
220@#: 0.0634801
220@#: -0.00448299
7-#a
#b
#c
+(54)
-(41)
xxnode->totalCount = 95
+[label with max classified samples @ this node]
entropy += 0.463245
entropy += 0.98645
+(71)
-(54)
xxnode->totalCount = 125
+[label with max classified samples @ this node]
entropy += 0.463509
entropy += 0.986617
32/////////////////////////////////////
## : 2
220@#: 0.542263
220@#: -0.018315
8-#a
#b
#c
+(34)
-(25)
xxnode->totalCount = 59
+[label with max classified samples @ this node]
entropy += 0.458239
entropy += 0.983149
+(96)
-(65)
xxnode->totalCount = 161
+[label with max classified samples @ this node]
entropy += 0.444793
entropy += 0.973089
32/////////////////////////////////////
## : 2
220@#: 0.704567
220@#: -0.00755736
9-#a
#b
#c
+(67)
-(46)
xxnode->totalCount = 113
+[label with max classified samples @ this node]
entropy += 0.447115
entropy += 0.974942
+(63)
-(44)
xxnode->totalCount = 107
+[label with max classified samples @ this node]
entropy += 0.449942
entropy += 0.977134
32/////////////////////////////////////
## : 2
220@#: 0.467464
220@#: -0.00777841

IG for each feature : 
-0.0139143, 0.704567, -0.00448299, -0.018315, -0.00755736, -0.00777841, 
max_IG = 0.704567 & splitOn_feature : 1
$$$$: decisionTree.size(): 3
$$$$: treeLevel_node : 2
$$$$: isLeaf_else: 0
$$$$: treeLevel_else: 3
$$$$: isLeaf_else: 0
$$$$: treeLevel_else: 3
4-#a
#b
#c
+(84)
-(56)
xxnode->totalCount = 140
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(34)
-(25)
xxnode->totalCount = 59
+[label with max classified samples @ this node]
entropy += 0.458239
entropy += 0.983149
32/////////////////////////////////////
## : 2
199@#: 0.972114
199@#: 0.680628
5-#a
#b
#c
+(86)
-(57)
xxnode->totalCount = 143
+[label with max classified samples @ this node]
entropy += 0.44119
entropy += 0.970127
+(32)
-(24)
xxnode->totalCount = 56
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
199@#: 0.274988
199@#: -0.00226201
6-#a
#b
#c
+(110)
-(75)
xxnode->totalCount = 185
+[label with max classified samples @ this node]
entropy += 0.445959
entropy += 0.974025
+(6)
-(8)
xxnode->totalCount = 14
-[label with max classified samples @ this node]
entropy += 0.523882
entropy += 0.985228
32/////////////////////////////////////
## : 2
199@#: 0.0666138
199@#: -0.00269877
7-#a
#b
#c
+(47)
-(38)
xxnode->totalCount = 85
+[label with max classified samples @ this node]
entropy += 0.472655
entropy += 0.991898
+(68)
-(46)
xxnode->totalCount = 114
+[label with max classified samples @ this node]
entropy += 0.444641
entropy += 0.972966
32/////////////////////////////////////
## : 2
199@#: 0.548439
199@#: -0.00893823
8-#a
#b
#c
+(32)
-(20)
xxnode->totalCount = 52
+[label with max classified samples @ this node]
entropy += 0.43104
entropy += 0.961237
+(88)
-(59)
xxnode->totalCount = 147
+[label with max classified samples @ this node]
entropy += 0.443137
entropy += 0.971741
32/////////////////////////////////////
## : 2
199@#: 0.720937
199@#: 0.0031182
9-#a
#b
#c
+(57)
-(42)
xxnode->totalCount = 99
+[label with max classified samples @ this node]
entropy += 0.458572
entropy += 0.983376
+(58)
-(42)
xxnode->totalCount = 100
+[label with max classified samples @ this node]
entropy += 0.455808
entropy += 0.981454
32/////////////////////////////////////
## : 2
199@#: 0.482897
199@#: -0.010296

IG for each feature : 
0.680628, -0.00226201, -0.00269877, -0.00893823, 0.0031182, -0.010296, 
max_IG = 0.680628 & splitOn_feature : 0
$$$$: decisionTree.size(): 4
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 3
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 3
4-#a
#b
#c
+(9)
-(9)
xxnode->totalCount = 18
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
24@#: 0.244985
24@#: 0.0154109
5-#a
#b
#c
+(8)
-(9)
xxnode->totalCount = 17
-[label with max classified samples @ this node]
entropy += 0.511747
entropy += 0.997503
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
24@#: 0.288421
24@#: 0.00106232
6-#a
#b
#c
+(11)
-(11)
xxnode->totalCount = 22
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
24@#: 0.0783182
24@#: -0.00501517
7-#a
#b
#c
+(5)
-(5)
xxnode->totalCount = 10
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(6)
-(8)
xxnode->totalCount = 14
-[label with max classified samples @ this node]
entropy += 0.523882
entropy += 0.985228
32/////////////////////////////////////
## : 2
24@#: 0.578318
24@#: 0.00360175
8-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(8)
-(8)
xxnode->totalCount = 16
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
24@#: 0.994985
24@#: 0.328318
9-#a
#b
#c
+(6)
-(8)
xxnode->totalCount = 14
-[label with max classified samples @ this node]
entropy += 0.523882
entropy += 0.985228
+(5)
-(5)
xxnode->totalCount = 10
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
24@#: 0.420268
24@#: 0.00360175

IG for each feature : 
0.0154109, 0.00106232, -0.00501517, 0.00360175, 0.328318, 0.00360175, 
max_IG = 0.328318 & splitOn_feature : 4
$$$$: decisionTree.size(): 4
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 3
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 3
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 4
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 3
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 3
Harry Potter*-------------------*-*-*-*--*-*--*-*
4-#a
#b
#c
+(69)
-(49)
xxnode->totalCount = 118
+[label with max classified samples @ this node]
entropy += 0.452663
entropy += 0.979177
+(26)
-(17)
xxnode->totalCount = 43
+[label with max classified samples @ this node]
entropy += 0.438871
entropy += 0.968165
32/////////////////////////////////////
## : 2
161@#: 0.255431
161@#: -0.00314711
5-#a
#b
#c
+(67)
-(46)
xxnode->totalCount = 113
+[label with max classified samples @ this node]
entropy += 0.447115
entropy += 0.974942
+(30)
-(18)
xxnode->totalCount = 48
+[label with max classified samples @ this node]
entropy += 0.423795
entropy += 0.954434
32/////////////////////////////////////
## : 2
161@#: 0.288813
161@#: 0.00426137
6-#a
#b
#c
+(90)
-(61)
xxnode->totalCount = 151
+[label with max classified samples @ this node]
entropy += 0.444965
entropy += 0.973228
+(5)
-(5)
xxnode->totalCount = 10
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
161@#: 0.0603102
161@#: -0.00180155
7-#a
#b
#c
+(38)
-(31)
xxnode->totalCount = 69
+[label with max classified samples @ this node]
entropy += 0.473952
entropy += 0.992563
+(51)
-(41)
xxnode->totalCount = 92
+[label with max classified samples @ this node]
entropy += 0.471826
entropy += 0.991461
32/////////////////////////////////////
## : 2
161@#: 0.547705
161@#: -0.0188442
8-#a
#b
#c
+(26)
-(17)
xxnode->totalCount = 43
+[label with max classified samples @ this node]
entropy += 0.438871
entropy += 0.968165
+(69)
-(49)
xxnode->totalCount = 118
+[label with max classified samples @ this node]
entropy += 0.452663
entropy += 0.979177
32/////////////////////////////////////
## : 2
161@#: 0.973089
161@#: 0.255431
9-#a
#b
#c
+(43)
-(38)
xxnode->totalCount = 81
+[label with max classified samples @ this node]
entropy += 0.48499
entropy += 0.99725
+(42)
-(38)
xxnode->totalCount = 80
+[label with max classified samples @ this node]
entropy += 0.488046
entropy += 0.998196
32/////////////////////////////////////
## : 2
161@#: 0.471367
161@#: -0.0246309

IG for each feature : 
-0.00314711, 0.00426137, -0.00180155, -0.0188442, 0.255431, -0.0246309, 
max_IG = 0.255431 & splitOn_feature : 4
$$$$: decisionTree.size(): 4
$$$$: treeLevel_node : 3
$$$$: isLeaf_else: 0
$$$$: treeLevel_else: 4
$$$$: isLeaf_else: 0
$$$$: treeLevel_else: 4
4-#a
#b
#c
+(26)
-(17)
xxnode->totalCount = 43
+[label with max classified samples @ this node]
entropy += 0.438871
entropy += 0.968165
+(8)
-(8)
xxnode->totalCount = 16
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
59@#: 0.277538
59@#: 0.0063511
5-#a
#b
#c
+(23)
-(17)
xxnode->totalCount = 40
+[label with max classified samples @ this node]
entropy += 0.459061
entropy += 0.983708
+(10)
-(9)
xxnode->totalCount = 19
+[label with max classified samples @ this node]
entropy += 0.487368
entropy += 0.998001
32/////////////////////////////////////
## : 2
59@#: 0.316228
59@#: -0.00516184
6-#a
#b
#c
+(32)
-(22)
xxnode->totalCount = 54
+[label with max classified samples @ this node]
entropy += 0.447341
entropy += 0.975119
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
59@#: 0.0906673
59@#: 0.00838332
7-#a
#b
#c
+(12)
-(13)
xxnode->totalCount = 25
-[label with max classified samples @ this node]
entropy += 0.508269
entropy += 0.998846
+(19)
-(15)
xxnode->totalCount = 34
+[label with max classified samples @ this node]
entropy += 0.469152
entropy += 0.989993
32/////////////////////////////////////
## : 2
59@#: 0.559909
59@#: -0.0105948
8-#a
#b
#c
+(8)
-(9)
xxnode->totalCount = 17
-[label with max classified samples @ this node]
entropy += 0.511747
entropy += 0.997503
+(25)
-(17)
xxnode->totalCount = 42
+[label with max classified samples @ this node]
entropy += 0.445513
entropy += 0.973668
32/////////////////////////////////////
## : 2
59@#: 0.983149
59@#: 0.290029
9-#a
#b
#c
+(16)
-(15)
xxnode->totalCount = 31
+[label with max classified samples @ this node]
entropy += 0.492488
entropy += 0.999249
+(15)
-(13)
xxnode->totalCount = 28
+[label with max classified samples @ this node]
entropy += 0.482392
entropy += 0.996317
32/////////////////////////////////////
## : 2
59@#: 0.45812
59@#: -0.0147083

IG for each feature : 
0.0063511, -0.00516184, 0.00838332, -0.0105948, 0.290029, -0.0147083, 
max_IG = 0.290029 & splitOn_feature : 4
$$$$: decisionTree.size(): 5
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 4
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 4
4-#a
#b
#c
+(59)
-(42)
xxnode->totalCount = 101
+[label with max classified samples @ this node]
entropy += 0.453055
entropy += 0.979466
+(23)
-(16)
xxnode->totalCount = 39
+[label with max classified samples @ this node]
entropy += 0.44929
entropy += 0.976635
32/////////////////////////////////////
## : 2
140@#: 0.264336
140@#: -0.0077269
5-#a
#b
#c
+(55)
-(41)
xxnode->totalCount = 96
+[label with max classified samples @ this node]
entropy += 0.460397
entropy += 0.984604
+(27)
-(17)
xxnode->totalCount = 44
+[label with max classified samples @ this node]
entropy += 0.432334
entropy += 0.962413
32/////////////////////////////////////
## : 2
140@#: 0.295794
140@#: -0.00667901
6-#a
#b
#c
+(74)
-(56)
xxnode->totalCount = 130
+[label with max classified samples @ this node]
entropy += 0.462736
entropy += 0.986126
+(5)
-(5)
xxnode->totalCount = 10
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
140@#: 0.0552621
140@#: -0.0161665
7-#a
#b
#c
+(35)
-(29)
xxnode->totalCount = 64
+[label with max classified samples @ this node]
entropy += 0.476173
entropy += 0.993651
+(40)
-(36)
xxnode->totalCount = 76
+[label with max classified samples @ this node]
entropy += 0.487368
entropy += 0.998001
32/////////////////////////////////////
## : 2
140@#: 0.51671
140@#: -0.0250616
8-#a
#b
#c
+(23)
-(15)
xxnode->totalCount = 38
+[label with max classified samples @ this node]
entropy += 0.438432
entropy += 0.967788
+(60)
-(42)
xxnode->totalCount = 102
+[label with max classified samples @ this node]
entropy += 0.450315
entropy += 0.977418
32/////////////////////////////////////
## : 2
140@#: 0.708265
140@#: -0.00385354
9-#a
#b
#c
+(38)
-(31)
xxnode->totalCount = 69
+[label with max classified samples @ this node]
entropy += 0.473952
entropy += 0.992563
+(38)
-(33)
xxnode->totalCount = 71
+[label with max classified samples @ this node]
entropy += 0.482664
entropy += 0.99642
32/////////////////////////////////////
## : 2
140@#: 0.481759
140@#: -0.0235683

IG for each feature : 
-0.0077269, -0.00667901, -0.0161665, -0.0250616, -0.00385354, -0.0235683, 
max_IG = -0.00385354 & splitOn_feature : 4
$$$$: decisionTree.size(): 5
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 4
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 4
4-#a
#b
#c
+(26)
-(17)
xxnode->totalCount = 43
+[label with max classified samples @ this node]
entropy += 0.438871
entropy += 0.968165
+(8)
-(8)
xxnode->totalCount = 16
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
59@#: 0.277538
59@#: 0.0063511
5-#a
#b
#c
+(23)
-(17)
xxnode->totalCount = 40
+[label with max classified samples @ this node]
entropy += 0.459061
entropy += 0.983708
+(10)
-(9)
xxnode->totalCount = 19
+[label with max classified samples @ this node]
entropy += 0.487368
entropy += 0.998001
32/////////////////////////////////////
## : 2
59@#: 0.316228
59@#: -0.00516184
6-#a
#b
#c
+(32)
-(22)
xxnode->totalCount = 54
+[label with max classified samples @ this node]
entropy += 0.447341
entropy += 0.975119
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
59@#: 0.0906673
59@#: 0.00838332
7-#a
#b
#c
+(12)
-(13)
xxnode->totalCount = 25
-[label with max classified samples @ this node]
entropy += 0.508269
entropy += 0.998846
+(19)
-(15)
xxnode->totalCount = 34
+[label with max classified samples @ this node]
entropy += 0.469152
entropy += 0.989993
32/////////////////////////////////////
## : 2
59@#: 0.559909
59@#: -0.0105948
8-#a
#b
#c
+(8)
-(9)
xxnode->totalCount = 17
-[label with max classified samples @ this node]
entropy += 0.511747
entropy += 0.997503
+(25)
-(17)
xxnode->totalCount = 42
+[label with max classified samples @ this node]
entropy += 0.445513
entropy += 0.973668
32/////////////////////////////////////
## : 2
59@#: 0.695733
59@#: 0.0026135
9-#a
#b
#c
+(16)
-(15)
xxnode->totalCount = 31
+[label with max classified samples @ this node]
entropy += 0.492488
entropy += 0.999249
+(15)
-(13)
xxnode->totalCount = 28
+[label with max classified samples @ this node]
entropy += 0.482392
entropy += 0.996317
32/////////////////////////////////////
## : 2
59@#: 0.45812
59@#: -0.0147083

IG for each feature : 
0.0063511, -0.00516184, 0.00838332, -0.0105948, 0.0026135, -0.0147083, 
max_IG = 0.00838332 & splitOn_feature : 2
$$$$: decisionTree.size(): 5
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 4
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 4
4-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
8@#: 0.393156
8@#: 0.0487949
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
6-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
7-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.5
8@#: 0
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
8@#: 0.655639
8@#: 0.0487949
9-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.311278
8@#: 0.0612781

IG for each feature : 
0.0487949, 0.137925, 0.137925, 0, 0.0487949, 0.0612781, 
max_IG = 0.137925 & splitOn_feature : 1
$$$$: decisionTree.size(): 5
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 4
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 4
4-#a
#b
#c
+(6)
-(6)
xxnode->totalCount = 12
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
16@#: 0.25
16@#: 0
5-#a
#b
#c
+(6)
-(5)
xxnode->totalCount = 11
+[label with max classified samples @ this node]
entropy += 0.476983
entropy += 0.99403
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
16@#: 0.316604
16@#: 0.0131822
6-#a
#b
#c
+(6)
-(8)
xxnode->totalCount = 14
-[label with max classified samples @ this node]
entropy += 0.523882
entropy += 0.985228
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
16@#: 0.137925
16@#: 0.0129254
7-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
32/////////////////////////////////////
## : 2
16@#: 0.568963
16@#: 0.0114824
8-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(6)
-(5)
xxnode->totalCount = 11
+[label with max classified samples @ this node]
entropy += 0.476983
entropy += 0.99403
32/////////////////////////////////////
## : 2
16@#: 0.696578
16@#: 0.0131822
9-#a
#b
#c
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
16@#: 0.44252
16@#: 0.0114824

IG for each feature : 
0, 0.0131822, 0.0129254, 0.0114824, 0.0131822, 0.0114824, 
max_IG = 0.0131822 & splitOn_feature : 4
$$$$: decisionTree.size(): 5
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 4
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 4
Harry Potter*-------------------*-*-*-*--*-*--*-*
4-#a
#b
#c
+(15)
-(14)
xxnode->totalCount = 29
+[label with max classified samples @ this node]
entropy += 0.491943
entropy += 0.999142
+(6)
-(8)
xxnode->totalCount = 14
-[label with max classified samples @ this node]
entropy += 0.523882
entropy += 0.985228
32/////////////////////////////////////
## : 2
43@#: 0.294325
43@#: -0.0264472
5-#a
#b
#c
+(17)
-(15)
xxnode->totalCount = 32
+[label with max classified samples @ this node]
entropy += 0.484785
entropy += 0.99718
+(6)
-(5)
xxnode->totalCount = 11
+[label with max classified samples @ this node]
entropy += 0.476983
entropy += 0.99403
32/////////////////////////////////////
## : 2
43@#: 0.226077
43@#: -0.0282098
6-#a
#b
#c
+(23)
-(15)
xxnode->totalCount = 38
+[label with max classified samples @ this node]
entropy += 0.438432
entropy += 0.967788
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
43@#: 0.11291
43@#: 8.57953e-06
7-#a
#b
#c
+(10)
-(9)
xxnode->totalCount = 19
+[label with max classified samples @ this node]
entropy += 0.487368
entropy += 0.998001
+(11)
-(13)
xxnode->totalCount = 24
-[label with max classified samples @ this node]
entropy += 0.515868
entropy += 0.994985
32/////////////////////////////////////
## : 2
43@#: 0.527188
43@#: -0.0281528
8-#a
#b
#c
+(5)
-(5)
xxnode->totalCount = 10
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(18)
-(15)
xxnode->totalCount = 33
+[label with max classified samples @ this node]
entropy += 0.476983
entropy += 0.99403
32/////////////////////////////////////
## : 2
43@#: 0.968165
43@#: 0.205304
9-#a
#b
#c
+(11)
-(12)
xxnode->totalCount = 23
-[label with max classified samples @ this node]
entropy += 0.508932
entropy += 0.998636
+(11)
-(9)
xxnode->totalCount = 20
+[label with max classified samples @ this node]
entropy += 0.474373
entropy += 0.992774
32/////////////////////////////////////
## : 2
43@#: 0.434011
43@#: -0.0277449

IG for each feature : 
-0.0264472, -0.0282098, 8.57953e-06, -0.0281528, 0.205304, -0.0277449, 
max_IG = 0.205304 & splitOn_feature : 4
$$$$: decisionTree.size(): 5
$$$$: treeLevel_node : 4
$$$$: isLeaf_else: 0
$$$$: treeLevel_else: 5
$$$$: isLeaf_else: 0
$$$$: treeLevel_else: 5
4-#a
#b
#c
+(47)
-(38)
xxnode->totalCount = 85
+[label with max classified samples @ this node]
entropy += 0.472655
entropy += 0.991898
+(18)
-(15)
xxnode->totalCount = 33
+[label with max classified samples @ this node]
entropy += 0.476983
entropy += 0.99403
32/////////////////////////////////////
## : 2
118@#: 0.264675
118@#: -0.0133169
5-#a
#b
#c
+(40)
-(38)
xxnode->totalCount = 78
+[label with max classified samples @ this node]
entropy += 0.494089
entropy += 0.999526
+(23)
-(17)
xxnode->totalCount = 40
+[label with max classified samples @ this node]
entropy += 0.459061
entropy += 0.983708
32/////////////////////////////////////
## : 2
118@#: 0.318474
118@#: -0.0149866
6-#a
#b
#c
+(67)
-(44)
xxnode->totalCount = 111
+[label with max classified samples @ this node]
entropy += 0.439621
entropy += 0.968804
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
118@#: 0.067845
118@#: 0.00939931
7-#a
#b
#c
+(32)
-(22)
xxnode->totalCount = 54
+[label with max classified samples @ this node]
entropy += 0.447341
entropy += 0.975119
+(35)
-(29)
xxnode->totalCount = 64
+[label with max classified samples @ this node]
entropy += 0.476173
entropy += 0.993651
32/////////////////////////////////////
## : 2
118@#: 0.532936
118@#: -0.00599292
8-#a
#b
#c
+(18)
-(15)
xxnode->totalCount = 33
+[label with max classified samples @ this node]
entropy += 0.476983
entropy += 0.99403
+(47)
-(38)
xxnode->totalCount = 85
+[label with max classified samples @ this node]
entropy += 0.472655
entropy += 0.991898
32/////////////////////////////////////
## : 2
118@#: 0.701186
118@#: -0.0133169
9-#a
#b
#c
+(34)
-(26)
xxnode->totalCount = 60
+[label with max classified samples @ this node]
entropy += 0.464342
entropy += 0.987138
+(34)
-(24)
xxnode->totalCount = 58
+[label with max classified samples @ this node]
entropy += 0.451683
entropy += 0.978449
32/////////////////////////////////////
## : 2
118@#: 0.979177
118@#: 0.498244

IG for each feature : 
-0.0133169, -0.0149866, 0.00939931, -0.00599292, -0.0133169, 0.498244, 
max_IG = 0.498244 & splitOn_feature : 5
$$$$: decisionTree.size(): 6
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 5
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 5
4-#a
#b
#c
+(6)
-(7)
xxnode->totalCount = 13
-[label with max classified samples @ this node]
entropy += 0.514836
entropy += 0.995727
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
17@#: 0.236064
17@#: 0.000769789
5-#a
#b
#c
+(6)
-(6)
xxnode->totalCount = 12
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
17@#: 0.29162
17@#: 0.00604649
6-#a
#b
#c
+(7)
-(8)
xxnode->totalCount = 15
-[label with max classified samples @ this node]
entropy += 0.513117
entropy += 0.996792
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
17@#: 0.117981
17@#: 0.000333459
7-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
32/////////////////////////////////////
## : 2
17@#: 0.526914
17@#: 0.00222699
8-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(6)
-(6)
xxnode->totalCount = 12
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
17@#: 0.711929
17@#: 0.00604649
9-#a
#b
#c
+(5)
-(5)
xxnode->totalCount = 10
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
17@#: 0.409267
17@#: 0.00358508

IG for each feature : 
0.000769789, 0.00604649, 0.000333459, 0.00222699, 0.00604649, 0.00358508, 
max_IG = 0.00604649 & splitOn_feature : 1
$$$$: decisionTree.size(): 6
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 5
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 5
4-#a
#b
#c
+(15)
-(13)
xxnode->totalCount = 28
+[label with max classified samples @ this node]
entropy += 0.482392
entropy += 0.996317
+(6)
-(8)
xxnode->totalCount = 14
-[label with max classified samples @ this node]
entropy += 0.523882
entropy += 0.985228
32/////////////////////////////////////
## : 2
42@#: 0.309457
42@#: -0.0189523
5-#a
#b
#c
+(16)
-(15)
xxnode->totalCount = 31
+[label with max classified samples @ this node]
entropy += 0.492488
entropy += 0.999249
+(6)
-(5)
xxnode->totalCount = 11
+[label with max classified samples @ this node]
entropy += 0.476983
entropy += 0.99403
32/////////////////////////////////////
## : 2
42@#: 0.236127
42@#: -0.0242143
6-#a
#b
#c
+(22)
-(15)
xxnode->totalCount = 37
+[label with max classified samples @ this node]
entropy += 0.445959
entropy += 0.974025
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
42@#: 0.115599
42@#: 9.18464e-06
7-#a
#b
#c
+(9)
-(9)
xxnode->totalCount = 18
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(11)
-(13)
xxnode->totalCount = 24
-[label with max classified samples @ this node]
entropy += 0.515868
entropy += 0.994985
32/////////////////////////////////////
## : 2
42@#: 0.545097
42@#: -0.0234661
8-#a
#b
#c
+(5)
-(5)
xxnode->totalCount = 10
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(17)
-(15)
xxnode->totalCount = 32
+[label with max classified samples @ this node]
entropy += 0.484785
entropy += 0.99718
32/////////////////////////////////////
## : 2
42@#: 0.735573
42@#: -0.0241837
9-#a
#b
#c
+(11)
-(12)
xxnode->totalCount = 23
-[label with max classified samples @ this node]
entropy += 0.508932
entropy += 0.998636
+(10)
-(9)
xxnode->totalCount = 19
+[label with max classified samples @ this node]
entropy += 0.487368
entropy += 0.998001
32/////////////////////////////////////
## : 2
42@#: 0.973668
42@#: 0.522191

IG for each feature : 
-0.0189523, -0.0242143, 9.18464e-06, -0.0234661, -0.0241837, 0.522191, 
max_IG = 0.522191 & splitOn_feature : 5
$$$$: decisionTree.size(): 6
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 5
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 5
4-#a
#b
#c
+(14)
-(13)
xxnode->totalCount = 27
+[label with max classified samples @ this node]
entropy += 0.491313
entropy += 0.99901
+(6)
-(5)
xxnode->totalCount = 11
+[label with max classified samples @ this node]
entropy += 0.476983
entropy += 0.99403
32/////////////////////////////////////
## : 2
38@#: 0.257965
38@#: -0.0297802
5-#a
#b
#c
+(15)
-(13)
xxnode->totalCount = 28
+[label with max classified samples @ this node]
entropy += 0.482392
entropy += 0.996317
+(5)
-(5)
xxnode->totalCount = 10
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
38@#: 0.233661
38@#: -0.0294974
6-#a
#b
#c
+(19)
-(15)
xxnode->totalCount = 34
+[label with max classified samples @ this node]
entropy += 0.469152
entropy += 0.989993
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
38@#: 0.0820054
38@#: -0.0232577
7-#a
#b
#c
+(8)
-(9)
xxnode->totalCount = 17
-[label with max classified samples @ this node]
entropy += 0.511747
entropy += 0.997503
+(11)
-(10)
xxnode->totalCount = 21
+[label with max classified samples @ this node]
entropy += 0.488654
entropy += 0.998364
32/////////////////////////////////////
## : 2
38@#: 0.521537
38@#: -0.03019
8-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(15)
-(15)
xxnode->totalCount = 30
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
38@#: 0.757262
38@#: -0.0322115
9-#a
#b
#c
+(11)
-(9)
xxnode->totalCount = 20
+[label with max classified samples @ this node]
entropy += 0.474373
entropy += 0.992774
+(9)
-(9)
xxnode->totalCount = 18
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
38@#: 0.445276
38@#: -0.0284086

IG for each feature : 
-0.0297802, -0.0294974, -0.0232577, -0.03019, -0.0322115, -0.0284086, 
max_IG = -0.0232577 & splitOn_feature : 2
$$$$: decisionTree.size(): 6
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 5
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 5
4-#a
#b
#c
+(38)
-(34)
xxnode->totalCount = 72
+[label with max classified samples @ this node]
entropy += 0.48661
entropy += 0.997772
+(15)
-(15)
xxnode->totalCount = 30
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
102@#: 0.977418
102@#: 0.6833
5-#a
#b
#c
+(38)
-(31)
xxnode->totalCount = 69
+[label with max classified samples @ this node]
entropy += 0.473952
entropy += 0.992563
+(18)
-(15)
xxnode->totalCount = 33
+[label with max classified samples @ this node]
entropy += 0.476983
entropy += 0.99403
32/////////////////////////////////////
## : 2
102@#: 0.977418
102@#: 0.65582
6-#a
#b
#c
+(54)
-(41)
xxnode->totalCount = 95
+[label with max classified samples @ this node]
entropy += 0.463245
entropy += 0.98645
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
102@#: 0.0586656
102@#: -0.00894809
7-#a
#b
#c
+(29)
-(18)
xxnode->totalCount = 47
+[label with max classified samples @ this node]
entropy += 0.429822
entropy += 0.960119
+(32)
-(23)
xxnode->totalCount = 55
+[label with max classified samples @ this node]
entropy += 0.454609
entropy += 0.980597
32/////////////////////////////////////
## : 2
102@#: 0.53501
102@#: 0.00625668
8-#a
#b
#c
+(14)
-(13)
xxnode->totalCount = 27
+[label with max classified samples @ this node]
entropy += 0.491313
entropy += 0.99901
+(39)
-(36)
xxnode->totalCount = 75
+[label with max classified samples @ this node]
entropy += 0.490577
entropy += 0.998846
32/////////////////////////////////////
## : 2
102@#: 0.712974
102@#: -0.0214713
9-#a
#b
#c
+(31)
-(19)
xxnode->totalCount = 50
+[label with max classified samples @ this node]
entropy += 0.427589
entropy += 0.958042
+(32)
-(20)
xxnode->totalCount = 52
+[label with max classified samples @ this node]
entropy += 0.43104
entropy += 0.961237
32/////////////////////////////////////
## : 2
102@#: 0.507789
102@#: 0.0177472

IG for each feature : 
0.6833, 0.65582, -0.00894809, 0.00625668, -0.0214713, 0.0177472, 
max_IG = 0.6833 & splitOn_feature : 0
$$$$: decisionTree.size(): 6
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 5
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 5
4-#a
#b
#c
+(23)
-(15)
xxnode->totalCount = 38
+[label with max classified samples @ this node]
entropy += 0.438432
entropy += 0.967788
+(8)
-(8)
xxnode->totalCount = 16
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
54@#: 0.294083
54@#: -0.00221356
5-#a
#b
#c
+(23)
-(15)
xxnode->totalCount = 38
+[label with max classified samples @ this node]
entropy += 0.438432
entropy += 0.967788
+(8)
-(8)
xxnode->totalCount = 16
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
54@#: 0.294083
54@#: -0.00221356
6-#a
#b
#c
+(30)
-(19)
xxnode->totalCount = 49
+[label with max classified samples @ this node]
entropy += 0.433359
entropy += 0.963336
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
54@#: 0.100981
54@#: 0.0110784
7-#a
#b
#c
+(11)
-(13)
xxnode->totalCount = 24
-[label with max classified samples @ this node]
entropy += 0.515868
entropy += 0.994985
+(15)
-(15)
xxnode->totalCount = 30
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
54@#: 0.532904
54@#: -0.022652
8-#a
#b
#c
+(6)
-(8)
xxnode->totalCount = 14
-[label with max classified samples @ this node]
entropy += 0.523882
entropy += 0.985228
+(23)
-(17)
xxnode->totalCount = 40
+[label with max classified samples @ this node]
entropy += 0.459061
entropy += 0.983708
32/////////////////////////////////////
## : 2
54@#: 0.975119
54@#: 0.246446
9-#a
#b
#c
+(15)
-(15)
xxnode->totalCount = 30
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(11)
-(13)
xxnode->totalCount = 24
-[label with max classified samples @ this node]
entropy += 0.515868
entropy += 0.994985
32/////////////////////////////////////
## : 2
54@#: 0.419564
54@#: -0.022652

IG for each feature : 
-0.00221356, -0.00221356, 0.0110784, -0.022652, 0.246446, -0.022652, 
max_IG = 0.246446 & splitOn_feature : 4
$$$$: decisionTree.size(): 6
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 5
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 5
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.0199731, 0.170951, 
max_IG = 0.170951 & splitOn_feature : 2
$$$$: decisionTree.size(): 6
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 5
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 5
4-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
7@#: 0.4138
7@#: 0.0202442
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
7@#: 0
7@#: 0
6-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
7@#: 0.198117
7@#: 0.198117
7-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.591673
7@#: 0.0202442
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.591673
7@#: 0.0202442
9-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.291692
7@#: 0.00597771

IG for each feature : 
0.0202442, 0, 0.198117, 0.0202442, 0.0202442, 0.00597771, 
max_IG = 0.198117 & splitOn_feature : 2
$$$$: decisionTree.size(): 6
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 5
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 5
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.0199731, 0.170951, 
max_IG = 0.170951 & splitOn_feature : 2
$$$$: decisionTree.size(): 6
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 5
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 5
4-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
11@#: 0.367067
11@#: 0.00343049
5-#a
#b
#c
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
11@#: 0.18315
11@#: 0.00133162
6-#a
#b
#c
+(5)
-(5)
xxnode->totalCount = 10
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
11@#: 0.0849393
11@#: 0.0849393
7-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
11@#: 0.493142
11@#: 0.0518004
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
11@#: 0.99403
11@#: 0.266757
9-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
11@#: 0.367067
11@#: 0.00343049

IG for each feature : 
0.00343049, 0.00133162, 0.0849393, 0.0518004, 0.266757, 0.00343049, 
max_IG = 0.266757 & splitOn_feature : 4
$$$$: decisionTree.size(): 6
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 5
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 5
Harry Potter*-------------------*-*-*-*--*-*--*-*
4-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
10@#: 0.449022
10@#: 0.0490225
5-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
10@#: 0.2
10@#: -5.55112e-17
6-#a
#b
#c
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
10@#: 0.108032
10@#: 0.108032
7-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
10@#: 0.514525
10@#: 0.0290494
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
10@#: 0.724511
10@#: 0.0348516
9-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
10@#: 0.31034
10@#: 0.0348516

IG for each feature : 
0.0490225, -5.55112e-17, 0.108032, 0.0290494, 0.0348516, 0.0348516, 
max_IG = 0.108032 & splitOn_feature : 2
$$$$: decisionTree.size(): 6
$$$$: treeLevel_node : 5
$$$$: isLeaf_else: 0
$$$$: treeLevel_else: 6
$$$$: isLeaf_if: 1
$$$$: treeLevel_if: 6
4-#a
#b
#c
+(11)
-(13)
xxnode->totalCount = 24
-[label with max classified samples @ this node]
entropy += 0.515868
entropy += 0.994985
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
32/////////////////////////////////////
## : 2
33@#: 0.270405
33@#: 0.000111411
5-#a
#b
#c
+(11)
-(13)
xxnode->totalCount = 24
-[label with max classified samples @ this node]
entropy += 0.515868
entropy += 0.994985
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
32/////////////////////////////////////
## : 2
33@#: 0.270405
33@#: 0.000111411
6-#a
#b
#c
+(16)
-(15)
xxnode->totalCount = 31
+[label with max classified samples @ this node]
entropy += 0.492488
entropy += 0.999249
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
33@#: 0.0553418
33@#: -0.00526429
7-#a
#b
#c
+(7)
-(8)
xxnode->totalCount = 15
-[label with max classified samples @ this node]
entropy += 0.513117
entropy += 0.996792
+(9)
-(9)
xxnode->totalCount = 18
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
33@#: 0.540943
33@#: -0.00451144
8-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(12)
-(13)
xxnode->totalCount = 25
-[label with max classified samples @ this node]
entropy += 0.508269
entropy += 0.998846
32/////////////////////////////////////
## : 2
33@#: 0.99403
33@#: 0.237329
9-#a
#b
#c
+(9)
-(9)
xxnode->totalCount = 18
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(7)
-(8)
xxnode->totalCount = 15
-[label with max classified samples @ this node]
entropy += 0.513117
entropy += 0.996792
32/////////////////////////////////////
## : 2
33@#: 0.448576
33@#: -0.00451144

IG for each feature : 
0.000111411, 0.000111411, -0.00526429, -0.00451144, 0.237329, -0.00451144, 
max_IG = 0.237329 & splitOn_feature : 4
$$$$: decisionTree.size(): 7
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 6
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 6
4-#a
#b
#c
+(27)
-(17)
xxnode->totalCount = 44
+[label with max classified samples @ this node]
entropy += 0.432334
entropy += 0.962413
+(8)
-(8)
xxnode->totalCount = 16
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
60@#: 0.281368
60@#: 0.0147018
5-#a
#b
#c
+(23)
-(17)
xxnode->totalCount = 40
+[label with max classified samples @ this node]
entropy += 0.459061
entropy += 0.983708
+(11)
-(9)
xxnode->totalCount = 20
+[label with max classified samples @ this node]
entropy += 0.474373
entropy += 0.992774
32/////////////////////////////////////
## : 2
60@#: 0.331332
60@#: 0.000407448
6-#a
#b
#c
+(32)
-(23)
xxnode->totalCount = 55
+[label with max classified samples @ this node]
entropy += 0.454609
entropy += 0.980597
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
60@#: 0.0882568
60@#: 0.00734424
7-#a
#b
#c
+(12)
-(13)
xxnode->totalCount = 25
-[label with max classified samples @ this node]
entropy += 0.508269
entropy += 0.998846
+(20)
-(15)
xxnode->totalCount = 35
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
60@#: 0.570952
60@#: -0.00376428
8-#a
#b
#c
+(9)
-(9)
xxnode->totalCount = 18
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(25)
-(17)
xxnode->totalCount = 42
+[label with max classified samples @ this node]
entropy += 0.445513
entropy += 0.973668
32/////////////////////////////////////
## : 2
60@#: 0.687138
60@#: 0.00557013
9-#a
#b
#c
+(16)
-(15)
xxnode->totalCount = 31
+[label with max classified samples @ this node]
entropy += 0.492488
entropy += 0.999249
+(15)
-(14)
xxnode->totalCount = 29
+[label with max classified samples @ this node]
entropy += 0.491943
entropy += 0.999142
32/////////////////////////////////////
## : 2
60@#: 0.470859
60@#: -0.0120597

IG for each feature : 
0.0147018, 0.000407448, 0.00734424, -0.00376428, 0.00557013, -0.0120597, 
max_IG = 0.0147018 & splitOn_feature : 0
$$$$: decisionTree.size(): 7
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 6
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 6
4-#a
#b
#c
+(25)
-(17)
xxnode->totalCount = 42
+[label with max classified samples @ this node]
entropy += 0.445513
entropy += 0.973668
+(8)
-(8)
xxnode->totalCount = 16
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
58@#: 0.273379
58@#: -0.00248272
5-#a
#b
#c
+(23)
-(17)
xxnode->totalCount = 40
+[label with max classified samples @ this node]
entropy += 0.459061
entropy += 0.983708
+(9)
-(9)
xxnode->totalCount = 18
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
58@#: 0.30003
58@#: -0.010315
6-#a
#b
#c
+(32)
-(21)
xxnode->totalCount = 53
+[label with max classified samples @ this node]
entropy += 0.439499
entropy += 0.9687
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
58@#: 0.0932576
58@#: 0.009555
7-#a
#b
#c
+(12)
-(13)
xxnode->totalCount = 25
-[label with max classified samples @ this node]
entropy += 0.508269
entropy += 0.998846
+(18)
-(15)
xxnode->totalCount = 33
+[label with max classified samples @ this node]
entropy += 0.476983
entropy += 0.99403
32/////////////////////////////////////
## : 2
58@#: 0.547912
58@#: -0.0176565
8-#a
#b
#c
+(8)
-(8)
xxnode->totalCount = 16
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(25)
-(17)
xxnode->totalCount = 42
+[label with max classified samples @ this node]
entropy += 0.445513
entropy += 0.973668
32/////////////////////////////////////
## : 2
58@#: 0.978449
58@#: 0.273379
9-#a
#b
#c
+(16)
-(15)
xxnode->totalCount = 31
+[label with max classified samples @ this node]
entropy += 0.492488
entropy += 0.999249
+(14)
-(13)
xxnode->totalCount = 27
+[label with max classified samples @ this node]
entropy += 0.491313
entropy += 0.99901
32/////////////////////////////////////
## : 2
58@#: 0.978449
58@#: 0.513393

IG for each feature : 
-0.00248272, -0.010315, 0.009555, -0.0176565, 0.273379, 0.513393, 
max_IG = 0.513393 & splitOn_feature : 5
$$$$: decisionTree.size(): 7
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 6
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 6
4-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
12@#: 0.333333
12@#: 5.55112e-17
5-#a
#b
#c
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
12@#: 0.256693
12@#: 0.027119
6-#a
#b
#c
+(6)
-(5)
xxnode->totalCount = 11
+[label with max classified samples @ this node]
entropy += 0.476983
entropy += 0.99403
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
12@#: 0.0888056
12@#: 0.0888056
7-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
12@#: 0.540852
12@#: 0.0817042
8-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
12@#: 1
12@#: 0.333333
9-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
12@#: 0.425284
12@#: 0.0207208

IG for each feature : 
5.55112e-17, 0.027119, 0.0888056, 0.0817042, 0.333333, 0.0207208, 
max_IG = 0.333333 & splitOn_feature : 4
$$$$: decisionTree.size(): 7
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 6
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 6
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.419973
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.419973, 0.170951, 
max_IG = 0.419973 & splitOn_feature : 4
$$$$: decisionTree.size(): 7
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 6
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 6
4-#a
#b
#c
+(8)
-(9)
xxnode->totalCount = 17
-[label with max classified samples @ this node]
entropy += 0.511747
entropy += 0.997503
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
23@#: 0.261351
23@#: 0.021796
5-#a
#b
#c
+(8)
-(8)
xxnode->totalCount = 16
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
23@#: 0.302984
23@#: 0.00313175
6-#a
#b
#c
+(11)
-(10)
xxnode->totalCount = 21
+[label with max classified samples @ this node]
entropy += 0.488654
entropy += 0.998364
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
23@#: 0.0870865
23@#: 0.000130002
7-#a
#b
#c
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
+(6)
-(8)
xxnode->totalCount = 14
-[label with max classified samples @ this node]
entropy += 0.523882
entropy += 0.985228
32/////////////////////////////////////
## : 2
23@#: 0.610824
23@#: 0.0111195
8-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(7)
-(8)
xxnode->totalCount = 15
-[label with max classified samples @ this node]
entropy += 0.513117
entropy += 0.996792
32/////////////////////////////////////
## : 2
23@#: 0.998636
23@#: 0.348554
9-#a
#b
#c
+(6)
-(8)
xxnode->totalCount = 14
-[label with max classified samples @ this node]
entropy += 0.523882
entropy += 0.985228
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
32/////////////////////////////////////
## : 2
23@#: 0.398932
23@#: 0.0111195

IG for each feature : 
0.021796, 0.00313175, 0.000130002, 0.0111195, 0.348554, 0.0111195, 
max_IG = 0.348554 & splitOn_feature : 4
$$$$: decisionTree.size(): 7
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 6
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 6
4-#a
#b
#c
+(7)
-(8)
xxnode->totalCount = 15
-[label with max classified samples @ this node]
entropy += 0.513117
entropy += 0.996792
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
19@#: 0.21106
19@#: 0.000533806
5-#a
#b
#c
+(6)
-(7)
xxnode->totalCount = 13
-[label with max classified samples @ this node]
entropy += 0.514836
entropy += 0.995727
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
19@#: 0.316714
19@#: 0.0267255
6-#a
#b
#c
+(8)
-(9)
xxnode->totalCount = 17
-[label with max classified samples @ this node]
entropy += 0.511747
entropy += 0.997503
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
19@#: 0.105499
19@#: 0.000235448
7-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(6)
-(5)
xxnode->totalCount = 11
+[label with max classified samples @ this node]
entropy += 0.476983
entropy += 0.99403
32/////////////////////////////////////
## : 2
19@#: 0.576948
19@#: 0.00145708
8-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(6)
-(8)
xxnode->totalCount = 14
-[label with max classified samples @ this node]
entropy += 0.523882
entropy += 0.985228
32/////////////////////////////////////
## : 2
19@#: 0.998001
19@#: 0.272043
9-#a
#b
#c
+(6)
-(6)
xxnode->totalCount = 12
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
19@#: 0.366422
19@#: 0.00344315

IG for each feature : 
0.000533806, 0.0267255, 0.000235448, 0.00145708, 0.272043, 0.00344315, 
max_IG = 0.272043 & splitOn_feature : 4
$$$$: decisionTree.size(): 7
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 6
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 6
4-#a
#b
#c
+(12)
-(13)
xxnode->totalCount = 25
-[label with max classified samples @ this node]
entropy += 0.508269
entropy += 0.998846
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
32/////////////////////////////////////
## : 2
34@#: 0.255548
34@#: -0.00679612
5-#a
#b
#c
+(12)
-(13)
xxnode->totalCount = 25
-[label with max classified samples @ this node]
entropy += 0.508269
entropy += 0.998846
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
32/////////////////////////////////////
## : 2
34@#: 0.255548
34@#: -0.00679612
6-#a
#b
#c
+(17)
-(15)
xxnode->totalCount = 32
+[label with max classified samples @ this node]
entropy += 0.484785
entropy += 0.99718
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
34@#: 0.0514701
34@#: -0.00735347
7-#a
#b
#c
+(7)
-(8)
xxnode->totalCount = 15
-[label with max classified samples @ this node]
entropy += 0.513117
entropy += 0.996792
+(10)
-(9)
xxnode->totalCount = 19
+[label with max classified samples @ this node]
entropy += 0.487368
entropy += 0.998001
32/////////////////////////////////////
## : 2
34@#: 0.550232
34@#: -0.0074746
8-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(13)
-(13)
xxnode->totalCount = 26
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
34@#: 0.989993
34@#: 0.225287
9-#a
#b
#c
+(10)
-(9)
xxnode->totalCount = 19
+[label with max classified samples @ this node]
entropy += 0.487368
entropy += 0.998001
+(7)
-(8)
xxnode->totalCount = 15
-[label with max classified samples @ this node]
entropy += 0.513117
entropy += 0.996792
32/////////////////////////////////////
## : 2
34@#: 0.432286
34@#: -0.0074746

IG for each feature : 
-0.00679612, -0.00679612, -0.00735347, -0.0074746, 0.225287, -0.0074746, 
max_IG = 0.225287 & splitOn_feature : 4
$$$$: decisionTree.size(): 7
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 6
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 6
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0, 0.311278, 
max_IG = 0.311278 & splitOn_feature : 2
$$$$: decisionTree.size(): 7
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 6
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 6
4-#a
#b
#c
+(29)
-(18)
xxnode->totalCount = 47
+[label with max classified samples @ this node]
entropy += 0.429822
entropy += 0.960119
+(12)
-(13)
xxnode->totalCount = 25
-[label with max classified samples @ this node]
entropy += 0.508269
entropy += 0.998846
32/////////////////////////////////////
## : 2
72@#: 0.371028
72@#: 0.024207
5-#a
#b
#c
+(29)
-(18)
xxnode->totalCount = 47
+[label with max classified samples @ this node]
entropy += 0.429822
entropy += 0.960119
+(12)
-(13)
xxnode->totalCount = 25
-[label with max classified samples @ this node]
entropy += 0.508269
entropy += 0.998846
32/////////////////////////////////////
## : 2
72@#: 0.371028
72@#: 0.024207
6-#a
#b
#c
+(36)
-(31)
xxnode->totalCount = 67
+[label with max classified samples @ this node]
entropy += 0.481521
entropy += 0.995979
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
72@#: 0.0709587
72@#: 0.0035316
7-#a
#b
#c
+(17)
-(15)
xxnode->totalCount = 32
+[label with max classified samples @ this node]
entropy += 0.484785
entropy += 0.99718
+(23)
-(17)
xxnode->totalCount = 40
+[label with max classified samples @ this node]
entropy += 0.459061
entropy += 0.983708
32/////////////////////////////////////
## : 2
72@#: 0.554581
72@#: 0.00807659
8-#a
#b
#c
+(11)
-(11)
xxnode->totalCount = 22
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(31)
-(19)
xxnode->totalCount = 50
+[label with max classified samples @ this node]
entropy += 0.427589
entropy += 0.958042
32/////////////////////////////////////
## : 2
72@#: 0.692217
72@#: 0.02691
9-#a
#b
#c
+(22)
-(15)
xxnode->totalCount = 37
+[label with max classified samples @ this node]
entropy += 0.445959
entropy += 0.974025
+(20)
-(15)
xxnode->totalCount = 35
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
72@#: 0.497232
72@#: 0.0183016

IG for each feature : 
0.024207, 0.024207, 0.0035316, 0.00807659, 0.02691, 0.0183016, 
max_IG = 0.02691 & splitOn_feature : 4
$$$$: decisionTree.size(): 7
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 6
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 6
4-#a
#b
#c
+(11)
-(11)
xxnode->totalCount = 22
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
30@#: 0.266667
30@#: 5.55112e-17
5-#a
#b
#c
+(11)
-(11)
xxnode->totalCount = 22
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
30@#: 0.266667
30@#: 5.55112e-17
6-#a
#b
#c
+(15)
-(13)
xxnode->totalCount = 28
+[label with max classified samples @ this node]
entropy += 0.482392
entropy += 0.996317
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
30@#: 0.0701046
30@#: 0.00343792
7-#a
#b
#c
+(6)
-(7)
xxnode->totalCount = 13
-[label with max classified samples @ this node]
entropy += 0.514836
entropy += 0.995727
+(8)
-(9)
xxnode->totalCount = 17
-[label with max classified samples @ this node]
entropy += 0.511747
entropy += 0.997503
32/////////////////////////////////////
## : 2
30@#: 0.568518
30@#: 0.00326666
8-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(11)
-(11)
xxnode->totalCount = 22
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
30@#: 1
30@#: 0.266667
9-#a
#b
#c
+(8)
-(8)
xxnode->totalCount = 16
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(6)
-(8)
xxnode->totalCount = 14
-[label with max classified samples @ this node]
entropy += 0.523882
entropy += 0.985228
32/////////////////////////////////////
## : 2
30@#: 0.466667
30@#: 0.00689354

IG for each feature : 
5.55112e-17, 5.55112e-17, 0.00343792, 0.00326666, 0.266667, 0.00689354, 
max_IG = 0.266667 & splitOn_feature : 4
$$$$: decisionTree.size(): 7
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 6
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 6
4-#a
#b
#c
+(5)
-(5)
xxnode->totalCount = 10
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
14@#: 0.270942
14@#: -0.0147719
5-#a
#b
#c
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
14@#: 0.348108
14@#: 0.00133974
6-#a
#b
#c
+(6)
-(6)
xxnode->totalCount = 12
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
14@#: 0.128085
14@#: -0.0147719
7-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
14@#: 0.591673
14@#: 0.0202442
8-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
32/////////////////////////////////////
## : 2
14@#: 0.985228
14@#: 0.348108
9-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
14@#: 0.492614
14@#: 0

IG for each feature : 
-0.0147719, 0.00133974, -0.0147719, 0.0202442, 0.348108, 0, 
max_IG = 0.348108 & splitOn_feature : 4
$$$$: decisionTree.size(): 7
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 6
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 6
4-#a
#b
#c
+(14)
-(13)
xxnode->totalCount = 27
+[label with max classified samples @ this node]
entropy += 0.491313
entropy += 0.99901
+(6)
-(7)
xxnode->totalCount = 13
-[label with max classified samples @ this node]
entropy += 0.514836
entropy += 0.995727
32/////////////////////////////////////
## : 2
40@#: 0.309376
40@#: -0.0142351
5-#a
#b
#c
+(15)
-(14)
xxnode->totalCount = 29
+[label with max classified samples @ this node]
entropy += 0.491943
entropy += 0.999142
+(6)
-(5)
xxnode->totalCount = 11
+[label with max classified samples @ this node]
entropy += 0.476983
entropy += 0.99403
32/////////////////////////////////////
## : 2
40@#: 0.25933
40@#: -0.0140281
6-#a
#b
#c
+(21)
-(15)
xxnode->totalCount = 36
+[label with max classified samples @ this node]
entropy += 0.453604
entropy += 0.979869
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
40@#: 0.101826
40@#: 0.00182638
7-#a
#b
#c
+(8)
-(9)
xxnode->totalCount = 17
-[label with max classified samples @ this node]
entropy += 0.511747
entropy += 0.997503
+(11)
-(12)
xxnode->totalCount = 23
-[label with max classified samples @ this node]
entropy += 0.508932
entropy += 0.998636
32/////////////////////////////////////
## : 2
40@#: 0.55977
40@#: -0.014446
8-#a
#b
#c
+(5)
-(5)
xxnode->totalCount = 10
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(15)
-(15)
xxnode->totalCount = 30
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
40@#: 0.983708
40@#: 0.233708
9-#a
#b
#c
+(11)
-(11)
xxnode->totalCount = 22
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(9)
-(9)
xxnode->totalCount = 18
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
40@#: 0.433708
40@#: -0.0162917

IG for each feature : 
-0.0142351, -0.0140281, 0.00182638, -0.014446, 0.233708, -0.0162917, 
max_IG = 0.233708 & splitOn_feature : 4
$$$$: decisionTree.size(): 7
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 6
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 6
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.5
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0.5, 0.311278, 
max_IG = 0.5 & splitOn_feature : 4
$$$$: decisionTree.size(): 7
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 6
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 6
4-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
6@#: 0.459148
6@#: 0
5-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
6@#: 0
6@#: 0
6-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
6@#: 0.10917
6@#: 0.10917
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.584963
6@#: -0.0817042
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.918296
6@#: 0.251629
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.918296
6@#: 0.584963

IG for each feature : 
0, 0, 0.10917, -0.0817042, 0.251629, 0.584963, 
max_IG = 0.584963 & splitOn_feature : 5
$$$$: decisionTree.size(): 7
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 6
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 6
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.5
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0.5, 0.311278, 
max_IG = 0.5 & splitOn_feature : 4
$$$$: decisionTree.size(): 7
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 6
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 6
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 7
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 6
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 6
4-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
8@#: 0.393156
8@#: 0.0487949
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
6-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
7-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.5
8@#: 0
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
8@#: 1
8@#: 0.393156
9-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.311278
8@#: 0.0612781

IG for each feature : 
0.0487949, 0.137925, 0.137925, 0, 0.393156, 0.0612781, 
max_IG = 0.393156 & splitOn_feature : 4
$$$$: decisionTree.size(): 7
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 6
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 6
Harry Potter*-------------------*-*-*-*--*-*--*-*
4-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
9@#: 0.378879
9@#: 0.0727802
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
9@#: 0.224788
9@#: 0.00256529
6-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
9@#: 0.102187
9@#: 0.102187
7-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
9@#: 0.546632
9@#: 0.00721462
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
9@#: 0.991076
9@#: 0.378879
9-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
9@#: 0.378879
9@#: 0.0727802

IG for each feature : 
0.0727802, 0.00256529, 0.102187, 0.00721462, 0.378879, 0.0727802, 
max_IG = 0.378879 & splitOn_feature : 4
$$$$: decisionTree.size(): 7
$$$$: treeLevel_node : 6
$$$$: isLeaf_else: 0
$$$$: treeLevel_else: 7
$$$$: isLeaf_else: 0
$$$$: treeLevel_else: 7
4-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
8@#: 0.393156
8@#: 0.0487949
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
6-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
7-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.5
8@#: 0
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
8@#: 1
8@#: 0.393156
9-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.311278
8@#: 0.0612781

IG for each feature : 
0.0487949, 0.137925, 0.137925, 0, 0.393156, 0.0612781, 
max_IG = 0.393156 & splitOn_feature : 4
$$$$: decisionTree.size(): 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
4-#a
#b
#c
+(10)
-(9)
xxnode->totalCount = 19
+[label with max classified samples @ this node]
entropy += 0.487368
entropy += 0.998001
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
25@#: 0.240365
25@#: 0.0199739
5-#a
#b
#c
+(9)
-(9)
xxnode->totalCount = 18
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
25@#: 0.278846
25@#: 0.00298166
6-#a
#b
#c
+(11)
-(12)
xxnode->totalCount = 23
-[label with max classified samples @ this node]
entropy += 0.508932
entropy += 0.998636
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
25@#: 0.0801004
25@#: 0.000100449
7-#a
#b
#c
+(6)
-(5)
xxnode->totalCount = 11
+[label with max classified samples @ this node]
entropy += 0.476983
entropy += 0.99403
+(6)
-(8)
xxnode->totalCount = 14
-[label with max classified samples @ this node]
entropy += 0.523882
entropy += 0.985228
32/////////////////////////////////////
## : 2
25@#: 0.561472
25@#: 0.00974449
8-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(8)
-(9)
xxnode->totalCount = 17
-[label with max classified samples @ this node]
entropy += 0.511747
entropy += 0.997503
32/////////////////////////////////////
## : 2
25@#: 0.678846
25@#: 0.000543804
9-#a
#b
#c
+(6)
-(8)
xxnode->totalCount = 14
-[label with max classified samples @ this node]
entropy += 0.523882
entropy += 0.985228
+(6)
-(5)
xxnode->totalCount = 11
+[label with max classified samples @ this node]
entropy += 0.476983
entropy += 0.99403
32/////////////////////////////////////
## : 2
25@#: 0.447118
25@#: 0.00974449

IG for each feature : 
0.0199739, 0.00298166, 0.000100449, 0.00974449, 0.000543804, 0.00974449, 
max_IG = 0.0199739 & splitOn_feature : 0
$$$$: decisionTree.size(): 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
4-#a
#b
#c
+(15)
-(15)
xxnode->totalCount = 30
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(6)
-(8)
xxnode->totalCount = 14
-[label with max classified samples @ this node]
entropy += 0.523882
entropy += 0.985228
32/////////////////////////////////////
## : 2
44@#: 0.280595
44@#: -0.0328871
5-#a
#b
#c
+(17)
-(15)
xxnode->totalCount = 32
+[label with max classified samples @ this node]
entropy += 0.484785
entropy += 0.99718
+(6)
-(6)
xxnode->totalCount = 12
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
44@#: 0.237191
44@#: -0.0355366
6-#a
#b
#c
+(23)
-(16)
xxnode->totalCount = 39
+[label with max classified samples @ this node]
entropy += 0.44929
entropy += 0.976635
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
44@#: 0.0967591
44@#: -0.0135762
7-#a
#b
#c
+(10)
-(9)
xxnode->totalCount = 19
+[label with max classified samples @ this node]
entropy += 0.487368
entropy += 0.998001
+(12)
-(13)
xxnode->totalCount = 25
-[label with max classified samples @ this node]
entropy += 0.508269
entropy += 0.998846
32/////////////////////////////////////
## : 2
44@#: 0.531458
44@#: -0.0360681
8-#a
#b
#c
+(6)
-(5)
xxnode->totalCount = 11
+[label with max classified samples @ this node]
entropy += 0.476983
entropy += 0.99403
+(18)
-(15)
xxnode->totalCount = 33
+[label with max classified samples @ this node]
entropy += 0.476983
entropy += 0.99403
32/////////////////////////////////////
## : 2
44@#: 0.713905
44@#: -0.0316175
9-#a
#b
#c
+(11)
-(13)
xxnode->totalCount = 24
-[label with max classified samples @ this node]
entropy += 0.515868
entropy += 0.994985
+(11)
-(9)
xxnode->totalCount = 20
+[label with max classified samples @ this node]
entropy += 0.474373
entropy += 0.992774
32/////////////////////////////////////
## : 2
44@#: 0.419694
44@#: -0.0315674

IG for each feature : 
-0.0328871, -0.0355366, -0.0135762, -0.0360681, -0.0316175, -0.0315674, 
max_IG = -0.0135762 & splitOn_feature : 2
$$$$: decisionTree.size(): 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
4-#a
#b
#c
+(6)
-(6)
xxnode->totalCount = 12
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
16@#: 0.25
16@#: 0
5-#a
#b
#c
+(6)
-(5)
xxnode->totalCount = 11
+[label with max classified samples @ this node]
entropy += 0.476983
entropy += 0.99403
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
16@#: 0.316604
16@#: 0.0131822
6-#a
#b
#c
+(6)
-(8)
xxnode->totalCount = 14
-[label with max classified samples @ this node]
entropy += 0.523882
entropy += 0.985228
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
16@#: 0.137925
16@#: 0.0129254
7-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
32/////////////////////////////////////
## : 2
16@#: 0.568963
16@#: 0.0114824
8-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(6)
-(5)
xxnode->totalCount = 11
+[label with max classified samples @ this node]
entropy += 0.476983
entropy += 0.99403
32/////////////////////////////////////
## : 2
16@#: 0.696578
16@#: 0.0131822
9-#a
#b
#c
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
16@#: 0.44252
16@#: 0.0114824

IG for each feature : 
0, 0.0131822, 0.0129254, 0.0114824, 0.0131822, 0.0114824, 
max_IG = 0.0131822 & splitOn_feature : 4
$$$$: decisionTree.size(): 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
4-#a
#b
#c
+(11)
-(12)
xxnode->totalCount = 23
-[label with max classified samples @ this node]
entropy += 0.508932
entropy += 0.998636
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
31@#: 0.258326
31@#: 0.000261275
5-#a
#b
#c
+(11)
-(12)
xxnode->totalCount = 23
-[label with max classified samples @ this node]
entropy += 0.508932
entropy += 0.998636
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
31@#: 0.258326
31@#: 0.000261275
6-#a
#b
#c
+(15)
-(14)
xxnode->totalCount = 29
+[label with max classified samples @ this node]
entropy += 0.491943
entropy += 0.999142
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
31@#: 0.0645679
31@#: 5.17959e-05
7-#a
#b
#c
+(6)
-(7)
xxnode->totalCount = 13
-[label with max classified samples @ this node]
entropy += 0.514836
entropy += 0.995727
+(9)
-(9)
xxnode->totalCount = 18
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
31@#: 0.581686
31@#: 0.00104096
8-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(11)
-(12)
xxnode->totalCount = 23
-[label with max classified samples @ this node]
entropy += 0.508932
entropy += 0.998636
32/////////////////////////////////////
## : 2
31@#: 0.999249
31@#: 0.258326
9-#a
#b
#c
+(8)
-(9)
xxnode->totalCount = 17
-[label with max classified samples @ this node]
entropy += 0.511747
entropy += 0.997503
+(6)
-(8)
xxnode->totalCount = 14
-[label with max classified samples @ this node]
entropy += 0.523882
entropy += 0.985228
32/////////////////////////////////////
## : 2
31@#: 0.452232
31@#: 0.00728998

IG for each feature : 
0.000261275, 0.000261275, 5.17959e-05, 0.00104096, 0.258326, 0.00728998, 
max_IG = 0.258326 & splitOn_feature : 4
$$$$: decisionTree.size(): 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
4-#a
#b
#c
+(10)
-(9)
xxnode->totalCount = 19
+[label with max classified samples @ this node]
entropy += 0.487368
entropy += 0.998001
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
27@#: 0.296713
27@#: 0.000417056
5-#a
#b
#c
+(11)
-(9)
xxnode->totalCount = 20
+[label with max classified samples @ this node]
entropy += 0.474373
entropy += 0.992774
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
27@#: 0.263622
27@#: 0.00819227
6-#a
#b
#c
+(12)
-(13)
xxnode->totalCount = 25
-[label with max classified samples @ this node]
entropy += 0.508269
entropy += 0.998846
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
27@#: 0.0741533
27@#: 7.9219e-05
7-#a
#b
#c
+(6)
-(5)
xxnode->totalCount = 11
+[label with max classified samples @ this node]
entropy += 0.476983
entropy += 0.99403
+(8)
-(8)
xxnode->totalCount = 16
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
27@#: 0.594035
27@#: 0.00144241
8-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(10)
-(9)
xxnode->totalCount = 19
+[label with max classified samples @ this node]
entropy += 0.487368
entropy += 0.998001
32/////////////////////////////////////
## : 2
27@#: 0.99901
27@#: 0.296713
9-#a
#b
#c
+(8)
-(8)
xxnode->totalCount = 16
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(6)
-(5)
xxnode->totalCount = 11
+[label with max classified samples @ this node]
entropy += 0.476983
entropy += 0.99403
32/////////////////////////////////////
## : 2
27@#: 0.406418
27@#: 0.00144241

IG for each feature : 
0.000417056, 0.00819227, 7.9219e-05, 0.00144241, 0.296713, 0.00144241, 
max_IG = 0.296713 & splitOn_feature : 4
$$$$: decisionTree.size(): 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0, 0.311278, 
max_IG = 0.311278 & splitOn_feature : 2
$$$$: decisionTree.size(): 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 7
4-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
8@#: 0.393156
8@#: 0.0487949
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
6-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
7-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.5
8@#: 0
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
8@#: 0.655639
8@#: 0.0487949
9-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.311278
8@#: 0.0612781

IG for each feature : 
0.0487949, 0.137925, 0.137925, 0, 0.0487949, 0.0612781, 
max_IG = 0.137925 & splitOn_feature : 1
$$$$: decisionTree.size(): 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 7
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 8
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 7
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 7
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.918296
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.918296, 0, 
max_IG = 0.918296 & splitOn_feature : 4
$$$$: decisionTree.size(): 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 7
4-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
8@#: 0.393156
8@#: 0.0487949
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
6-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
7-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.5
8@#: 0
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
8@#: 1
8@#: 0.393156
9-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.311278
8@#: 0.0612781

IG for each feature : 
0.0487949, 0.137925, 0.137925, 0, 0.393156, 0.0612781, 
max_IG = 0.393156 & splitOn_feature : 4
$$$$: decisionTree.size(): 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
4-#a
#b
#c
+(6)
-(5)
xxnode->totalCount = 11
+[label with max classified samples @ this node]
entropy += 0.476983
entropy += 0.99403
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
15@#: 0.267836
15@#: 0.00116948
5-#a
#b
#c
+(5)
-(5)
xxnode->totalCount = 10
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
15@#: 0.330125
15@#: 0.00647477
6-#a
#b
#c
+(6)
-(7)
xxnode->totalCount = 13
-[label with max classified samples @ this node]
entropy += 0.514836
entropy += 0.995727
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
15@#: 0.133828
15@#: 0.000494507
7-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
15@#: 0.537019
15@#: 0.00368517
8-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(5)
-(5)
xxnode->totalCount = 10
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
15@#: 0.673141
15@#: 0.00647477
9-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
15@#: 0.463458
15@#: 0.00368517

IG for each feature : 
0.00116948, 0.00647477, 0.000494507, 0.00368517, 0.00647477, 0.00368517, 
max_IG = 0.00647477 & splitOn_feature : 1
$$$$: decisionTree.size(): 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.419973
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.419973, 0.170951, 
max_IG = 0.419973 & splitOn_feature : 4
$$$$: decisionTree.size(): 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
4-#a
#b
#c
+(5)
-(5)
xxnode->totalCount = 10
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
14@#: 0.270942
14@#: -0.0147719
5-#a
#b
#c
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
14@#: 0.348108
14@#: 0.00133974
6-#a
#b
#c
+(6)
-(6)
xxnode->totalCount = 12
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
14@#: 0.128085
14@#: -0.0147719
7-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
14@#: 0.591673
14@#: 0.0202442
8-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
32/////////////////////////////////////
## : 2
14@#: 0.63846
14@#: 0.00133974
9-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
14@#: 0.492614
14@#: 0

IG for each feature : 
-0.0147719, 0.00133974, -0.0147719, 0.0202442, 0.00133974, 0, 
max_IG = 0.0202442 & splitOn_feature : 3
$$$$: decisionTree.size(): 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
4-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
8@#: 0.393156
8@#: 0.0487949
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
6-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
7-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.5
8@#: 0
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
8@#: 0.655639
8@#: 0.0487949
9-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.311278
8@#: 0.0612781

IG for each feature : 
0.0487949, 0.137925, 0.137925, 0, 0.0487949, 0.0612781, 
max_IG = 0.137925 & splitOn_feature : 1
$$$$: decisionTree.size(): 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 7
4-#a
#b
#c
+(10)
-(9)
xxnode->totalCount = 19
+[label with max classified samples @ this node]
entropy += 0.487368
entropy += 0.998001
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
26@#: 0.270692
26@#: 0.00543793
5-#a
#b
#c
+(10)
-(9)
xxnode->totalCount = 19
+[label with max classified samples @ this node]
entropy += 0.487368
entropy += 0.998001
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
26@#: 0.270692
26@#: 0.00543793
6-#a
#b
#c
+(11)
-(13)
xxnode->totalCount = 24
-[label with max classified samples @ this node]
entropy += 0.515868
entropy += 0.994985
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
26@#: 0.0815525
26@#: 0.00462939
7-#a
#b
#c
+(6)
-(5)
xxnode->totalCount = 11
+[label with max classified samples @ this node]
entropy += 0.476983
entropy += 0.99403
+(7)
-(8)
xxnode->totalCount = 15
-[label with max classified samples @ this node]
entropy += 0.513117
entropy += 0.996792
32/////////////////////////////////////
## : 2
26@#: 0.579449
26@#: 0.00437666
8-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(9)
-(9)
xxnode->totalCount = 18
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
26@#: 1
26@#: 0.307692
9-#a
#b
#c
+(7)
-(8)
xxnode->totalCount = 15
-[label with max classified samples @ this node]
entropy += 0.513117
entropy += 0.996792
+(6)
-(5)
xxnode->totalCount = 11
+[label with max classified samples @ this node]
entropy += 0.476983
entropy += 0.99403
32/////////////////////////////////////
## : 2
26@#: 0.424928
26@#: 0.00437666

IG for each feature : 
0.00543793, 0.00543793, 0.00462939, 0.00437666, 0.307692, 0.00437666, 
max_IG = 0.307692 & splitOn_feature : 4
$$$$: decisionTree.size(): 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 8
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 7
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
4-#a
#b
#c
+(8)
-(8)
xxnode->totalCount = 16
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
22@#: 0.272727
22@#: 0.022283
5-#a
#b
#c
+(7)
-(8)
xxnode->totalCount = 15
-[label with max classified samples @ this node]
entropy += 0.513117
entropy += 0.996792
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
22@#: 0.320369
22@#: 0.00688766
6-#a
#b
#c
+(11)
-(9)
xxnode->totalCount = 20
+[label with max classified samples @ this node]
entropy += 0.474373
entropy += 0.992774
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
22@#: 0.0974778
22@#: 0.00656868
7-#a
#b
#c
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
+(6)
-(7)
xxnode->totalCount = 13
-[label with max classified samples @ this node]
entropy += 0.514836
entropy += 0.995727
32/////////////////////////////////////
## : 2
22@#: 0.59456
22@#: 0.00617539
8-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(7)
-(8)
xxnode->totalCount = 15
-[label with max classified samples @ this node]
entropy += 0.513117
entropy += 0.996792
32/////////////////////////////////////
## : 2
22@#: 1
22@#: 0.320369
9-#a
#b
#c
+(6)
-(7)
xxnode->totalCount = 13
-[label with max classified samples @ this node]
entropy += 0.514836
entropy += 0.995727
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
32/////////////////////////////////////
## : 2
22@#: 0.411616
22@#: 0.00617539

IG for each feature : 
0.022283, 0.00688766, 0.00656868, 0.00617539, 0.320369, 0.00617539, 
max_IG = 0.320369 & splitOn_feature : 4
$$$$: decisionTree.size(): 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
4-#a
#b
#c
+(20)
-(15)
xxnode->totalCount = 35
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(7)
-(8)
xxnode->totalCount = 15
-[label with max classified samples @ this node]
entropy += 0.513117
entropy += 0.996792
32/////////////////////////////////////
## : 2
50@#: 0.268382
50@#: -0.0306552
5-#a
#b
#c
+(21)
-(15)
xxnode->totalCount = 36
+[label with max classified samples @ this node]
entropy += 0.453604
entropy += 0.979869
+(6)
-(8)
xxnode->totalCount = 14
-[label with max classified samples @ this node]
entropy += 0.523882
entropy += 0.985228
32/////////////////////////////////////
## : 2
50@#: 0.252537
50@#: -0.0233274
6-#a
#b
#c
+(27)
-(18)
xxnode->totalCount = 45
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
50@#: 0.0841865
50@#: -0.0129086
7-#a
#b
#c
+(11)
-(12)
xxnode->totalCount = 23
-[label with max classified samples @ this node]
entropy += 0.508932
entropy += 0.998636
+(14)
-(13)
xxnode->totalCount = 27
+[label with max classified samples @ this node]
entropy += 0.491313
entropy += 0.99901
32/////////////////////////////////////
## : 2
50@#: 0.498669
50@#: -0.0407961
8-#a
#b
#c
+(6)
-(6)
xxnode->totalCount = 12
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(23)
-(15)
xxnode->totalCount = 38
+[label with max classified samples @ this node]
entropy += 0.438432
entropy += 0.967788
32/////////////////////////////////////
## : 2
50@#: 0.958042
50@#: 0.222523
9-#a
#b
#c
+(15)
-(13)
xxnode->totalCount = 28
+[label with max classified samples @ this node]
entropy += 0.482392
entropy += 0.996317
+(11)
-(11)
xxnode->totalCount = 22
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
50@#: 0.400105
50@#: -0.0398952

IG for each feature : 
-0.0306552, -0.0233274, -0.0129086, -0.0407961, 0.222523, -0.0398952, 
max_IG = 0.222523 & splitOn_feature : 4
$$$$: decisionTree.size(): 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
4-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
8@#: 0.393156
8@#: 0.0487949
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
6-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
7-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.5
8@#: 0
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
8@#: 0.655639
8@#: 0.0487949
9-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.311278
8@#: 0.0612781

IG for each feature : 
0.0487949, 0.137925, 0.137925, 0, 0.0487949, 0.0612781, 
max_IG = 0.137925 & splitOn_feature : 1
$$$$: decisionTree.size(): 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 7
4-#a
#b
#c
+(8)
-(8)
xxnode->totalCount = 16
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
22@#: 0.272727
22@#: 0.022283
5-#a
#b
#c
+(7)
-(8)
xxnode->totalCount = 15
-[label with max classified samples @ this node]
entropy += 0.513117
entropy += 0.996792
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
22@#: 0.320369
22@#: 0.00688766
6-#a
#b
#c
+(11)
-(9)
xxnode->totalCount = 20
+[label with max classified samples @ this node]
entropy += 0.474373
entropy += 0.992774
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
22@#: 0.0974778
22@#: 0.00656868
7-#a
#b
#c
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
+(6)
-(7)
xxnode->totalCount = 13
-[label with max classified samples @ this node]
entropy += 0.514836
entropy += 0.995727
32/////////////////////////////////////
## : 2
22@#: 0.59456
22@#: 0.00617539
8-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(7)
-(8)
xxnode->totalCount = 15
-[label with max classified samples @ this node]
entropy += 0.513117
entropy += 0.996792
32/////////////////////////////////////
## : 2
22@#: 0.686518
22@#: 0.00688766
9-#a
#b
#c
+(6)
-(7)
xxnode->totalCount = 13
-[label with max classified samples @ this node]
entropy += 0.514836
entropy += 0.995727
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
32/////////////////////////////////////
## : 2
22@#: 1
22@#: 0.59456

IG for each feature : 
0.022283, 0.00688766, 0.00656868, 0.00617539, 0.00688766, 0.59456, 
max_IG = 0.59456 & splitOn_feature : 5
$$$$: decisionTree.size(): 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.0199731, 0.170951, 
max_IG = 0.170951 & splitOn_feature : 2
$$$$: decisionTree.size(): 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 7
4-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
9@#: 0.378879
9@#: 0.0727802
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
9@#: 0.224788
9@#: 0.00256529
6-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
9@#: 0.102187
9@#: 0.102187
7-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
9@#: 0.546632
9@#: 0.00721462
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
9@#: 0.684977
9@#: 0.0727802
9-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
9@#: 0.378879
9@#: 0.0727802

IG for each feature : 
0.0727802, 0.00256529, 0.102187, 0.00721462, 0.0727802, 0.0727802, 
max_IG = 0.102187 & splitOn_feature : 2
$$$$: decisionTree.size(): 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 7
4-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
10@#: 0.449022
10@#: 0.0490225
5-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
10@#: 0.2
10@#: -5.55112e-17
6-#a
#b
#c
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
10@#: 0.108032
10@#: 0.108032
7-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
10@#: 0.514525
10@#: 0.0290494
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
10@#: 0.724511
10@#: 0.0348516
9-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
10@#: 0.31034
10@#: 0.0348516

IG for each feature : 
0.0490225, -5.55112e-17, 0.108032, 0.0290494, 0.0348516, 0.0348516, 
max_IG = 0.108032 & splitOn_feature : 2
$$$$: decisionTree.size(): 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 7
4-#a
#b
#c
+(11)
-(11)
xxnode->totalCount = 22
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
30@#: 0.266667
30@#: 5.55112e-17
5-#a
#b
#c
+(11)
-(11)
xxnode->totalCount = 22
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
30@#: 0.266667
30@#: 5.55112e-17
6-#a
#b
#c
+(15)
-(13)
xxnode->totalCount = 28
+[label with max classified samples @ this node]
entropy += 0.482392
entropy += 0.996317
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
30@#: 0.0701046
30@#: 0.00343792
7-#a
#b
#c
+(6)
-(7)
xxnode->totalCount = 13
-[label with max classified samples @ this node]
entropy += 0.514836
entropy += 0.995727
+(8)
-(9)
xxnode->totalCount = 17
-[label with max classified samples @ this node]
entropy += 0.511747
entropy += 0.997503
32/////////////////////////////////////
## : 2
30@#: 0.568518
30@#: 0.00326666
8-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(11)
-(11)
xxnode->totalCount = 22
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
30@#: 1
30@#: 0.266667
9-#a
#b
#c
+(8)
-(8)
xxnode->totalCount = 16
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(6)
-(8)
xxnode->totalCount = 14
-[label with max classified samples @ this node]
entropy += 0.523882
entropy += 0.985228
32/////////////////////////////////////
## : 2
30@#: 0.466667
30@#: 0.00689354

IG for each feature : 
5.55112e-17, 5.55112e-17, 0.00343792, 0.00326666, 0.266667, 0.00689354, 
max_IG = 0.266667 & splitOn_feature : 4
$$$$: decisionTree.size(): 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 8
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 7
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 7
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 8
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 7
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 7
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0, 0.311278, 
max_IG = 0.311278 & splitOn_feature : 2
$$$$: decisionTree.size(): 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 7
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 8
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 7
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 7
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 8
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 7
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 7
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 8
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 7
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 7
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 8
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 7
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 7
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 8
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 7
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.0199731, 0.170951, 
max_IG = 0.170951 & splitOn_feature : 2
$$$$: decisionTree.size(): 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 7
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 7
Harry Potter*-------------------*-*-*-*--*-*--*-*
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 8
$$$$: treeLevel_node : 7
$$$$: isLeaf_if: 1
$$$$: treeLevel_if: 8
$$$$: isLeaf_else: 0
$$$$: treeLevel_else: 8
4-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
6@#: 0.459148
6@#: 0
5-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
6@#: 0
6@#: 0
6-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
6@#: 0.10917
6@#: 0.10917
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.584963
6@#: -0.0817042
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.584963
6@#: -0.0817042
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.251629
6@#: -0.0817042

IG for each feature : 
0, 0, 0.10917, -0.0817042, -0.0817042, -0.0817042, 
max_IG = 0.10917 & splitOn_feature : 2
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 8
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.0199731, 0.170951, 
max_IG = 0.170951 & splitOn_feature : 2
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 8
4-#a
#b
#c
+(7)
-(8)
xxnode->totalCount = 15
-[label with max classified samples @ this node]
entropy += 0.513117
entropy += 0.996792
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
19@#: 0.21106
19@#: 0.000533806
5-#a
#b
#c
+(6)
-(7)
xxnode->totalCount = 13
-[label with max classified samples @ this node]
entropy += 0.514836
entropy += 0.995727
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
19@#: 0.316714
19@#: 0.0267255
6-#a
#b
#c
+(8)
-(9)
xxnode->totalCount = 17
-[label with max classified samples @ this node]
entropy += 0.511747
entropy += 0.997503
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
19@#: 0.105499
19@#: 0.000235448
7-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(6)
-(5)
xxnode->totalCount = 11
+[label with max classified samples @ this node]
entropy += 0.476983
entropy += 0.99403
32/////////////////////////////////////
## : 2
19@#: 0.576948
19@#: 0.00145708
8-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(6)
-(8)
xxnode->totalCount = 14
-[label with max classified samples @ this node]
entropy += 0.523882
entropy += 0.985228
32/////////////////////////////////////
## : 2
19@#: 0.998001
19@#: 0.272043
9-#a
#b
#c
+(6)
-(6)
xxnode->totalCount = 12
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
19@#: 0.366422
19@#: 0.00344315

IG for each feature : 
0.000533806, 0.0267255, 0.000235448, 0.00145708, 0.272043, 0.00344315, 
max_IG = 0.272043 & splitOn_feature : 4
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
4-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
6@#: 0.459148
6@#: 0
5-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
6@#: 0
6@#: 0
6-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
6@#: 0.10917
6@#: 0.10917
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.584963
6@#: -0.0817042
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.584963
6@#: -0.0817042
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.251629
6@#: -0.0817042

IG for each feature : 
0, 0, 0.10917, -0.0817042, -0.0817042, -0.0817042, 
max_IG = 0.10917 & splitOn_feature : 2
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 8
4-#a
#b
#c
+(14)
-(13)
xxnode->totalCount = 27
+[label with max classified samples @ this node]
entropy += 0.491313
entropy += 0.99901
+(6)
-(6)
xxnode->totalCount = 12
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
39@#: 0.285012
39@#: -0.0226799
5-#a
#b
#c
+(15)
-(13)
xxnode->totalCount = 28
+[label with max classified samples @ this node]
entropy += 0.482392
entropy += 0.996317
+(6)
-(5)
xxnode->totalCount = 11
+[label with max classified samples @ this node]
entropy += 0.476983
entropy += 0.99403
32/////////////////////////////////////
## : 2
39@#: 0.261331
39@#: -0.0190368
6-#a
#b
#c
+(20)
-(15)
xxnode->totalCount = 35
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
39@#: 0.0924558
39@#: -0.0101083
7-#a
#b
#c
+(8)
-(9)
xxnode->totalCount = 17
-[label with max classified samples @ this node]
entropy += 0.511747
entropy += 0.997503
+(11)
-(11)
xxnode->totalCount = 22
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
39@#: 0.541826
39@#: -0.0222765
8-#a
#b
#c
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
+(15)
-(15)
xxnode->totalCount = 30
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
39@#: 0.976635
39@#: 0.207404
9-#a
#b
#c
+(11)
-(10)
xxnode->totalCount = 21
+[label with max classified samples @ this node]
entropy += 0.488654
entropy += 0.998364
+(9)
-(9)
xxnode->totalCount = 18
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
39@#: 0.439054
39@#: -0.022484

IG for each feature : 
-0.0226799, -0.0190368, -0.0101083, -0.0222765, 0.207404, -0.022484, 
max_IG = 0.207404 & splitOn_feature : 4
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.419973
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.419973, 0.170951, 
max_IG = 0.419973 & splitOn_feature : 4
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.419973
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.419973, 0.170951, 
max_IG = 0.419973 & splitOn_feature : 4
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
4-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
11@#: 0.367067
11@#: 0.00343049
5-#a
#b
#c
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
11@#: 0.18315
11@#: 0.00133162
6-#a
#b
#c
+(5)
-(5)
xxnode->totalCount = 10
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
11@#: 0.0849393
11@#: 0.0849393
7-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
11@#: 0.493142
11@#: 0.0518004
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
11@#: 0.99403
11@#: 0.266757
9-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
11@#: 0.367067
11@#: 0.00343049

IG for each feature : 
0.00343049, 0.00133162, 0.0849393, 0.0518004, 0.266757, 0.00343049, 
max_IG = 0.266757 & splitOn_feature : 4
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
4-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
8@#: 0.393156
8@#: 0.0487949
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
6-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
7-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.5
8@#: 0
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
8@#: 1
8@#: 0.393156
9-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.311278
8@#: 0.0612781

IG for each feature : 
0.0487949, 0.137925, 0.137925, 0, 0.393156, 0.0612781, 
max_IG = 0.393156 & splitOn_feature : 4
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
4-#a
#b
#c
+(8)
-(9)
xxnode->totalCount = 17
-[label with max classified samples @ this node]
entropy += 0.511747
entropy += 0.997503
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
23@#: 0.261351
23@#: 0.021796
5-#a
#b
#c
+(8)
-(8)
xxnode->totalCount = 16
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
23@#: 0.302984
23@#: 0.00313175
6-#a
#b
#c
+(11)
-(10)
xxnode->totalCount = 21
+[label with max classified samples @ this node]
entropy += 0.488654
entropy += 0.998364
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
23@#: 0.0870865
23@#: 0.000130002
7-#a
#b
#c
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
+(6)
-(8)
xxnode->totalCount = 14
-[label with max classified samples @ this node]
entropy += 0.523882
entropy += 0.985228
32/////////////////////////////////////
## : 2
23@#: 0.610824
23@#: 0.0111195
8-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(7)
-(8)
xxnode->totalCount = 15
-[label with max classified samples @ this node]
entropy += 0.513117
entropy += 0.996792
32/////////////////////////////////////
## : 2
23@#: 0.998636
23@#: 0.348554
9-#a
#b
#c
+(6)
-(8)
xxnode->totalCount = 14
-[label with max classified samples @ this node]
entropy += 0.523882
entropy += 0.985228
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
32/////////////////////////////////////
## : 2
23@#: 0.398932
23@#: 0.0111195

IG for each feature : 
0.021796, 0.00313175, 0.000130002, 0.0111195, 0.348554, 0.0111195, 
max_IG = 0.348554 & splitOn_feature : 4
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
4-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
8@#: 0.393156
8@#: 0.0487949
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
6-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
7-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.5
8@#: 0
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
8@#: 0.655639
8@#: 0.0487949
9-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.311278
8@#: 0.0612781

IG for each feature : 
0.0487949, 0.137925, 0.137925, 0, 0.0487949, 0.0612781, 
max_IG = 0.137925 & splitOn_feature : 1
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 8
4-#a
#b
#c
+(7)
-(8)
xxnode->totalCount = 15
-[label with max classified samples @ this node]
entropy += 0.513117
entropy += 0.996792
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
19@#: 0.21106
19@#: 0.000533806
5-#a
#b
#c
+(6)
-(7)
xxnode->totalCount = 13
-[label with max classified samples @ this node]
entropy += 0.514836
entropy += 0.995727
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
19@#: 0.316714
19@#: 0.0267255
6-#a
#b
#c
+(8)
-(9)
xxnode->totalCount = 17
-[label with max classified samples @ this node]
entropy += 0.511747
entropy += 0.997503
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
19@#: 0.105499
19@#: 0.000235448
7-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(6)
-(5)
xxnode->totalCount = 11
+[label with max classified samples @ this node]
entropy += 0.476983
entropy += 0.99403
32/////////////////////////////////////
## : 2
19@#: 0.576948
19@#: 0.00145708
8-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(6)
-(8)
xxnode->totalCount = 14
-[label with max classified samples @ this node]
entropy += 0.523882
entropy += 0.985228
32/////////////////////////////////////
## : 2
19@#: 0.998001
19@#: 0.272043
9-#a
#b
#c
+(6)
-(6)
xxnode->totalCount = 12
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
19@#: 0.366422
19@#: 0.00344315

IG for each feature : 
0.000533806, 0.0267255, 0.000235448, 0.00145708, 0.272043, 0.00344315, 
max_IG = 0.272043 & splitOn_feature : 4
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.918296
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.918296, 0, 
max_IG = 0.918296 & splitOn_feature : 4
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 8
4-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
7@#: 0.4138
7@#: 0.0202442
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
7@#: 0
7@#: 0
6-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
7@#: 0.198117
7@#: 0.198117
7-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.591673
7@#: 0.0202442
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.985228
7@#: 0.4138
9-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.291692
7@#: 0.00597771

IG for each feature : 
0.0202442, 0, 0.198117, 0.0202442, 0.4138, 0.00597771, 
max_IG = 0.4138 & splitOn_feature : 4
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 8
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 8
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.918296
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.918296, 0, 
max_IG = 0.918296 & splitOn_feature : 4
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 8
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.419973
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.419973, 0.170951, 
max_IG = 0.419973 & splitOn_feature : 4
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
4-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
10@#: 0.449022
10@#: 0.0490225
5-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
10@#: 0.2
10@#: -5.55112e-17
6-#a
#b
#c
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
10@#: 0.108032
10@#: 0.108032
7-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
10@#: 0.514525
10@#: 0.0290494
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
10@#: 0.724511
10@#: 0.0348516
9-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
10@#: 0.31034
10@#: 0.0348516

IG for each feature : 
0.0490225, -5.55112e-17, 0.108032, 0.0290494, 0.0348516, 0.0348516, 
max_IG = 0.108032 & splitOn_feature : 2
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 8
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.0199731, 0.170951, 
max_IG = 0.170951 & splitOn_feature : 2
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 8
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 8
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 8
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.918296
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.918296, 0, 
max_IG = 0.918296 & splitOn_feature : 4
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 8
4-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
6@#: 0.459148
6@#: 0
5-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
6@#: 0
6@#: 0
6-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
6@#: 0.10917
6@#: 0.10917
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.584963
6@#: -0.0817042
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.584963
6@#: -0.0817042
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.251629
6@#: -0.0817042

IG for each feature : 
0, 0, 0.10917, -0.0817042, -0.0817042, -0.0817042, 
max_IG = 0.10917 & splitOn_feature : 2
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 8
4-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
8@#: 0.393156
8@#: 0.0487949
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
6-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
7-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.5
8@#: 0
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
8@#: 0.655639
8@#: 0.0487949
9-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.311278
8@#: 0.0612781

IG for each feature : 
0.0487949, 0.137925, 0.137925, 0, 0.0487949, 0.0612781, 
max_IG = 0.137925 & splitOn_feature : 1
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 8
4-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
7@#: 0.4138
7@#: 0.0202442
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
7@#: 0
7@#: 0
6-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
7@#: 0.198117
7@#: 0.198117
7-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.591673
7@#: 0.0202442
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.591673
7@#: 0.0202442
9-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.291692
7@#: 0.00597771

IG for each feature : 
0.0202442, 0, 0.198117, 0.0202442, 0.0202442, 0.00597771, 
max_IG = 0.198117 & splitOn_feature : 2
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 8
4-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
8@#: 0.393156
8@#: 0.0487949
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
6-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
7-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.5
8@#: 0
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
8@#: 0.655639
8@#: 0.0487949
9-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.311278
8@#: 0.0612781

IG for each feature : 
0.0487949, 0.137925, 0.137925, 0, 0.0487949, 0.0612781, 
max_IG = 0.137925 & splitOn_feature : 1
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 8
4-#a
#b
#c
+(6)
-(8)
xxnode->totalCount = 14
-[label with max classified samples @ this node]
entropy += 0.523882
entropy += 0.985228
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
18@#: 0.233711
18@#: 0.0114892
5-#a
#b
#c
+(6)
-(7)
xxnode->totalCount = 13
-[label with max classified samples @ this node]
entropy += 0.514836
entropy += 0.995727
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
18@#: 0.280864
18@#: 0.011155
6-#a
#b
#c
+(8)
-(8)
xxnode->totalCount = 16
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
18@#: 0.111111
18@#: 5.55112e-17
7-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(5)
-(5)
xxnode->totalCount = 10
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
18@#: 0.555556
18@#: 0
8-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(6)
-(7)
xxnode->totalCount = 13
-[label with max classified samples @ this node]
entropy += 0.514836
entropy += 0.995727
32/////////////////////////////////////
## : 2
18@#: 1
18@#: 0.280864
9-#a
#b
#c
+(6)
-(5)
xxnode->totalCount = 11
+[label with max classified samples @ this node]
entropy += 0.476983
entropy += 0.99403
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
18@#: 0.392537
18@#: 0.00939282

IG for each feature : 
0.0114892, 0.011155, 5.55112e-17, 0, 0.280864, 0.00939282, 
max_IG = 0.280864 & splitOn_feature : 4
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 8
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 8
4-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
7@#: 0.4138
7@#: 0.0202442
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
7@#: 0
7@#: 0
6-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
7@#: 0.198117
7@#: 0.198117
7-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.591673
7@#: 0.0202442
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.591673
7@#: 0.0202442
9-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.291692
7@#: 0.00597771

IG for each feature : 
0.0202442, 0, 0.198117, 0.0202442, 0.0202442, 0.00597771, 
max_IG = 0.198117 & splitOn_feature : 2
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 8
4-#a
#b
#c
+(6)
-(5)
xxnode->totalCount = 11
+[label with max classified samples @ this node]
entropy += 0.476983
entropy += 0.99403
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
15@#: 0.267836
15@#: 0.00116948
5-#a
#b
#c
+(5)
-(5)
xxnode->totalCount = 10
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
15@#: 0.330125
15@#: 0.00647477
6-#a
#b
#c
+(6)
-(7)
xxnode->totalCount = 13
-[label with max classified samples @ this node]
entropy += 0.514836
entropy += 0.995727
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
15@#: 0.133828
15@#: 0.000494507
7-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
15@#: 0.537019
15@#: 0.00368517
8-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(5)
-(5)
xxnode->totalCount = 10
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
15@#: 0.996792
15@#: 0.330125
9-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
15@#: 0.463458
15@#: 0.00368517

IG for each feature : 
0.00116948, 0.00647477, 0.000494507, 0.00368517, 0.330125, 0.00368517, 
max_IG = 0.330125 & splitOn_feature : 4
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
4-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
12@#: 0.333333
12@#: 5.55112e-17
5-#a
#b
#c
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
12@#: 0.256693
12@#: 0.027119
6-#a
#b
#c
+(6)
-(5)
xxnode->totalCount = 11
+[label with max classified samples @ this node]
entropy += 0.476983
entropy += 0.99403
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
12@#: 0.0888056
12@#: 0.0888056
7-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
12@#: 0.540852
12@#: 0.0817042
8-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
12@#: 1
12@#: 0.333333
9-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
12@#: 1
12@#: 0.595437

IG for each feature : 
5.55112e-17, 0.027119, 0.0888056, 0.0817042, 0.333333, 0.595437, 
max_IG = 0.595437 & splitOn_feature : 5
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
4-#a
#b
#c
+(14)
-(13)
xxnode->totalCount = 27
+[label with max classified samples @ this node]
entropy += 0.491313
entropy += 0.99901
+(6)
-(5)
xxnode->totalCount = 11
+[label with max classified samples @ this node]
entropy += 0.476983
entropy += 0.99403
32/////////////////////////////////////
## : 2
38@#: 0.257965
38@#: -0.0297802
5-#a
#b
#c
+(15)
-(13)
xxnode->totalCount = 28
+[label with max classified samples @ this node]
entropy += 0.482392
entropy += 0.996317
+(5)
-(5)
xxnode->totalCount = 10
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
38@#: 0.233661
38@#: -0.0294974
6-#a
#b
#c
+(19)
-(15)
xxnode->totalCount = 34
+[label with max classified samples @ this node]
entropy += 0.469152
entropy += 0.989993
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
38@#: 0.0820054
38@#: -0.0232577
7-#a
#b
#c
+(8)
-(9)
xxnode->totalCount = 17
-[label with max classified samples @ this node]
entropy += 0.511747
entropy += 0.997503
+(11)
-(10)
xxnode->totalCount = 21
+[label with max classified samples @ this node]
entropy += 0.488654
entropy += 0.998364
32/////////////////////////////////////
## : 2
38@#: 0.521537
38@#: -0.03019
8-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(15)
-(15)
xxnode->totalCount = 30
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
38@#: 0.967788
38@#: 0.178315
9-#a
#b
#c
+(11)
-(9)
xxnode->totalCount = 20
+[label with max classified samples @ this node]
entropy += 0.474373
entropy += 0.992774
+(9)
-(9)
xxnode->totalCount = 18
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
38@#: 0.445276
38@#: -0.0284086

IG for each feature : 
-0.0297802, -0.0294974, -0.0232577, -0.03019, 0.178315, -0.0284086, 
max_IG = 0.178315 & splitOn_feature : 4
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
4-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
7@#: 0.4138
7@#: 0.0202442
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
7@#: 0
7@#: 0
6-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
7@#: 0.198117
7@#: 0.198117
7-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.591673
7@#: 0.0202442
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.591673
7@#: 0.0202442
9-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.985228
7@#: 0.699514

IG for each feature : 
0.0202442, 0, 0.198117, 0.0202442, 0.0202442, 0.699514, 
max_IG = 0.699514 & splitOn_feature : 5
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
4-#a
#b
#c
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
13@#: 0.309598
13@#: 0.00190556
5-#a
#b
#c
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
13@#: 0.309598
13@#: 0.00190556
6-#a
#b
#c
+(6)
-(6)
xxnode->totalCount = 12
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
13@#: 0.0726505
13@#: 0.0726505
7-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
13@#: 0.571899
13@#: 0.0413911
8-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
13@#: 0.995727
13@#: 0.380343
9-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
13@#: 0.46522
13@#: 0.0413911

IG for each feature : 
0.00190556, 0.00190556, 0.0726505, 0.0413911, 0.380343, 0.0413911, 
max_IG = 0.380343 & splitOn_feature : 4
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
4-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
9@#: 0.378879
9@#: 0.0727802
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
9@#: 0.224788
9@#: 0.00256529
6-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
9@#: 0.102187
9@#: 0.102187
7-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
9@#: 0.546632
9@#: 0.00721462
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
9@#: 0.991076
9@#: 0.378879
9-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
9@#: 0.378879
9@#: 0.0727802

IG for each feature : 
0.0727802, 0.00256529, 0.102187, 0.00721462, 0.378879, 0.0727802, 
max_IG = 0.378879 & splitOn_feature : 4
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.5
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0.5, 0.311278, 
max_IG = 0.5 & splitOn_feature : 4
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
4-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
8@#: 0.393156
8@#: 0.0487949
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
6-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
7-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.5
8@#: 0
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
8@#: 0.655639
8@#: 0.0487949
9-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.311278
8@#: 0.0612781

IG for each feature : 
0.0487949, 0.137925, 0.137925, 0, 0.0487949, 0.0612781, 
max_IG = 0.137925 & splitOn_feature : 1
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 8
4-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
9@#: 0.378879
9@#: 0.0727802
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
9@#: 0.224788
9@#: 0.00256529
6-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
9@#: 0.102187
9@#: 0.102187
7-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
9@#: 0.546632
9@#: 0.00721462
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
9@#: 0.684977
9@#: 0.0727802
9-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
9@#: 0.378879
9@#: 0.0727802

IG for each feature : 
0.0727802, 0.00256529, 0.102187, 0.00721462, 0.0727802, 0.0727802, 
max_IG = 0.102187 & splitOn_feature : 2
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 8
4-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
8@#: 0.393156
8@#: 0.0487949
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
6-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
7-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.5
8@#: 0
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
8@#: 0.655639
8@#: 0.0487949
9-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.311278
8@#: 0.0612781

IG for each feature : 
0.0487949, 0.137925, 0.137925, 0, 0.0487949, 0.0612781, 
max_IG = 0.137925 & splitOn_feature : 1
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 8
4-#a
#b
#c
+(8)
-(8)
xxnode->totalCount = 16
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
22@#: 0.272727
22@#: 0.022283
5-#a
#b
#c
+(7)
-(8)
xxnode->totalCount = 15
-[label with max classified samples @ this node]
entropy += 0.513117
entropy += 0.996792
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
22@#: 0.320369
22@#: 0.00688766
6-#a
#b
#c
+(11)
-(9)
xxnode->totalCount = 20
+[label with max classified samples @ this node]
entropy += 0.474373
entropy += 0.992774
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
22@#: 0.0974778
22@#: 0.00656868
7-#a
#b
#c
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
+(6)
-(7)
xxnode->totalCount = 13
-[label with max classified samples @ this node]
entropy += 0.514836
entropy += 0.995727
32/////////////////////////////////////
## : 2
22@#: 0.59456
22@#: 0.00617539
8-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(7)
-(8)
xxnode->totalCount = 15
-[label with max classified samples @ this node]
entropy += 0.513117
entropy += 0.996792
32/////////////////////////////////////
## : 2
22@#: 1
22@#: 0.320369
9-#a
#b
#c
+(6)
-(7)
xxnode->totalCount = 13
-[label with max classified samples @ this node]
entropy += 0.514836
entropy += 0.995727
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
32/////////////////////////////////////
## : 2
22@#: 0.411616
22@#: 0.00617539

IG for each feature : 
0.022283, 0.00688766, 0.00656868, 0.00617539, 0.320369, 0.00617539, 
max_IG = 0.320369 & splitOn_feature : 4
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 8
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 8
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 8
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0, 0.311278, 
max_IG = 0.311278 & splitOn_feature : 2
$$$$: decisionTree.size(): 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 8
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 8
Harry Potter*-------------------*-*-*-*--*-*--*-*
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 9
$$$$: treeLevel_node : 8
$$$$: isLeaf_if: 1
$$$$: treeLevel_if: 9
$$$$: isLeaf_if: 1
$$$$: treeLevel_if: 9
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.0199731, 0.170951, 
max_IG = 0.170951 & splitOn_feature : 2
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.5
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0.5, 0.311278, 
max_IG = 0.5 & splitOn_feature : 4
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.0199731, 0.170951, 
max_IG = 0.170951 & splitOn_feature : 2
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
4-#a
#b
#c
+(5)
-(5)
xxnode->totalCount = 10
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
14@#: 0.270942
14@#: -0.0147719
5-#a
#b
#c
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
14@#: 0.348108
14@#: 0.00133974
6-#a
#b
#c
+(6)
-(6)
xxnode->totalCount = 12
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
14@#: 0.128085
14@#: -0.0147719
7-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
14@#: 0.591673
14@#: 0.0202442
8-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
32/////////////////////////////////////
## : 2
14@#: 0.985228
14@#: 0.348108
9-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
14@#: 0.492614
14@#: 0

IG for each feature : 
-0.0147719, 0.00133974, -0.0147719, 0.0202442, 0.348108, 0, 
max_IG = 0.348108 & splitOn_feature : 4
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.419973
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.419973, 0.170951, 
max_IG = 0.419973 & splitOn_feature : 4
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
4-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
9@#: 0.378879
9@#: 0.0727802
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
9@#: 0.224788
9@#: 0.00256529
6-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
9@#: 0.102187
9@#: 0.102187
7-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
9@#: 0.546632
9@#: 0.00721462
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
9@#: 0.684977
9@#: 0.0727802
9-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
9@#: 0.991076
9@#: 0.684977

IG for each feature : 
0.0727802, 0.00256529, 0.102187, 0.00721462, 0.0727802, 0.684977, 
max_IG = 0.684977 & splitOn_feature : 5
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
4-#a
#b
#c
+(11)
-(11)
xxnode->totalCount = 22
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
30@#: 0.266667
30@#: 5.55112e-17
5-#a
#b
#c
+(11)
-(11)
xxnode->totalCount = 22
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
30@#: 0.266667
30@#: 5.55112e-17
6-#a
#b
#c
+(15)
-(13)
xxnode->totalCount = 28
+[label with max classified samples @ this node]
entropy += 0.482392
entropy += 0.996317
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
30@#: 0.0701046
30@#: 0.00343792
7-#a
#b
#c
+(6)
-(7)
xxnode->totalCount = 13
-[label with max classified samples @ this node]
entropy += 0.514836
entropy += 0.995727
+(8)
-(9)
xxnode->totalCount = 17
-[label with max classified samples @ this node]
entropy += 0.511747
entropy += 0.997503
32/////////////////////////////////////
## : 2
30@#: 0.568518
30@#: 0.00326666
8-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(11)
-(11)
xxnode->totalCount = 22
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
30@#: 1
30@#: 0.266667
9-#a
#b
#c
+(8)
-(8)
xxnode->totalCount = 16
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(6)
-(8)
xxnode->totalCount = 14
-[label with max classified samples @ this node]
entropy += 0.523882
entropy += 0.985228
32/////////////////////////////////////
## : 2
30@#: 1
30@#: 0.540227

IG for each feature : 
5.55112e-17, 5.55112e-17, 0.00343792, 0.00326666, 0.266667, 0.540227, 
max_IG = 0.540227 & splitOn_feature : 5
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
4-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
8@#: 0.393156
8@#: 0.0487949
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
6-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
7-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.5
8@#: 0
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
8@#: 1
8@#: 0.393156
9-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.311278
8@#: 0.0612781

IG for each feature : 
0.0487949, 0.137925, 0.137925, 0, 0.393156, 0.0612781, 
max_IG = 0.393156 & splitOn_feature : 4
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.419973
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.419973, 0.170951, 
max_IG = 0.419973 & splitOn_feature : 4
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
4-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
8@#: 0.393156
8@#: 0.0487949
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
6-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
7-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.5
8@#: 0
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
8@#: 1
8@#: 0.393156
9-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.311278
8@#: 0.0612781

IG for each feature : 
0.0487949, 0.137925, 0.137925, 0, 0.393156, 0.0612781, 
max_IG = 0.393156 & splitOn_feature : 4
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
4-#a
#b
#c
+(6)
-(5)
xxnode->totalCount = 11
+[label with max classified samples @ this node]
entropy += 0.476983
entropy += 0.99403
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
15@#: 0.267836
15@#: 0.00116948
5-#a
#b
#c
+(5)
-(5)
xxnode->totalCount = 10
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
15@#: 0.330125
15@#: 0.00647477
6-#a
#b
#c
+(6)
-(7)
xxnode->totalCount = 13
-[label with max classified samples @ this node]
entropy += 0.514836
entropy += 0.995727
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
15@#: 0.133828
15@#: 0.000494507
7-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
15@#: 0.537019
15@#: 0.00368517
8-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(5)
-(5)
xxnode->totalCount = 10
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
15@#: 0.996792
15@#: 0.330125
9-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
15@#: 0.463458
15@#: 0.00368517

IG for each feature : 
0.00116948, 0.00647477, 0.000494507, 0.00368517, 0.330125, 0.00368517, 
max_IG = 0.330125 & splitOn_feature : 4
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
4-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
7@#: 0.4138
7@#: 0.0202442
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
7@#: 0
7@#: 0
6-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
7@#: 0.198117
7@#: 0.198117
7-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.591673
7@#: 0.0202442
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.591673
7@#: 0.0202442
9-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.291692
7@#: 0.00597771

IG for each feature : 
0.0202442, 0, 0.198117, 0.0202442, 0.0202442, 0.00597771, 
max_IG = 0.198117 & splitOn_feature : 2
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.0199731, 0.170951, 
max_IG = 0.170951 & splitOn_feature : 2
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
4-#a
#b
#c
+(5)
-(5)
xxnode->totalCount = 10
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
14@#: 0.270942
14@#: -0.0147719
5-#a
#b
#c
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
14@#: 0.348108
14@#: 0.00133974
6-#a
#b
#c
+(6)
-(6)
xxnode->totalCount = 12
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
14@#: 0.128085
14@#: -0.0147719
7-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
14@#: 0.591673
14@#: 0.0202442
8-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
32/////////////////////////////////////
## : 2
14@#: 0.985228
14@#: 0.348108
9-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
14@#: 0.492614
14@#: 0

IG for each feature : 
-0.0147719, 0.00133974, -0.0147719, 0.0202442, 0.348108, 0, 
max_IG = 0.348108 & splitOn_feature : 4
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0, 0.311278, 
max_IG = 0.311278 & splitOn_feature : 2
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.918296
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.918296, 0, 
max_IG = 0.918296 & splitOn_feature : 4
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
4-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
9@#: 0.378879
9@#: 0.0727802
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
9@#: 0.224788
9@#: 0.00256529
6-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
9@#: 0.102187
9@#: 0.102187
7-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
9@#: 0.546632
9@#: 0.00721462
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
9@#: 0.991076
9@#: 0.378879
9-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
9@#: 0.378879
9@#: 0.0727802

IG for each feature : 
0.0727802, 0.00256529, 0.102187, 0.00721462, 0.378879, 0.0727802, 
max_IG = 0.378879 & splitOn_feature : 4
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.5
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0.5, 0.311278, 
max_IG = 0.5 & splitOn_feature : 4
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.0199731, 0.170951, 
max_IG = 0.170951 & splitOn_feature : 2
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
4-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
7@#: 0.4138
7@#: 0.0202442
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
7@#: 0
7@#: 0
6-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
7@#: 0.198117
7@#: 0.198117
7-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.591673
7@#: 0.0202442
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.591673
7@#: 0.0202442
9-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.985228
7@#: 0.699514

IG for each feature : 
0.0202442, 0, 0.198117, 0.0202442, 0.0202442, 0.699514, 
max_IG = 0.699514 & splitOn_feature : 5
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
4-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
6@#: 0.459148
6@#: 0
5-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
6@#: 0
6@#: 0
6-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
6@#: 0.10917
6@#: 0.10917
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.584963
6@#: -0.0817042
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.918296
6@#: 0.251629
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.251629
6@#: -0.0817042

IG for each feature : 
0, 0, 0.10917, -0.0817042, 0.251629, -0.0817042, 
max_IG = 0.251629 & splitOn_feature : 4
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
4-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
7@#: 0.4138
7@#: 0.0202442
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
7@#: 0
7@#: 0
6-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
7@#: 0.198117
7@#: 0.198117
7-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.591673
7@#: 0.0202442
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.985228
7@#: 0.4138
9-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.291692
7@#: 0.00597771

IG for each feature : 
0.0202442, 0, 0.198117, 0.0202442, 0.4138, 0.00597771, 
max_IG = 0.4138 & splitOn_feature : 4
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.419973
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.419973, 0.170951, 
max_IG = 0.419973 & splitOn_feature : 4
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
4-#a
#b
#c
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
13@#: 0.309598
13@#: 0.00190556
5-#a
#b
#c
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
13@#: 0.309598
13@#: 0.00190556
6-#a
#b
#c
+(6)
-(6)
xxnode->totalCount = 12
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
13@#: 0.0726505
13@#: 0.0726505
7-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
13@#: 0.571899
13@#: 0.0413911
8-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
13@#: 0.995727
13@#: 0.380343
9-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
13@#: 0.46522
13@#: 0.0413911

IG for each feature : 
0.00190556, 0.00190556, 0.0726505, 0.0413911, 0.380343, 0.0413911, 
max_IG = 0.380343 & splitOn_feature : 4
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
4-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
6@#: 0.459148
6@#: 0
5-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
6@#: 0
6@#: 0
6-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
6@#: 0.10917
6@#: 0.10917
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.584963
6@#: -0.0817042
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.584963
6@#: -0.0817042
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.251629
6@#: -0.0817042

IG for each feature : 
0, 0, 0.10917, -0.0817042, -0.0817042, -0.0817042, 
max_IG = 0.10917 & splitOn_feature : 2
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.419973
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.419973, 0.170951, 
max_IG = 0.419973 & splitOn_feature : 4
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
4-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
10@#: 0.449022
10@#: 0.0490225
5-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
10@#: 0.2
10@#: -5.55112e-17
6-#a
#b
#c
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
10@#: 0.108032
10@#: 0.108032
7-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
10@#: 0.514525
10@#: 0.0290494
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
10@#: 0.724511
10@#: 0.0348516
9-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
10@#: 0.31034
10@#: 0.0348516

IG for each feature : 
0.0490225, -5.55112e-17, 0.108032, 0.0290494, 0.0348516, 0.0348516, 
max_IG = 0.108032 & splitOn_feature : 2
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
4-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
7@#: 0.4138
7@#: 0.0202442
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
7@#: 0
7@#: 0
6-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
7@#: 0.198117
7@#: 0.198117
7-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.591673
7@#: 0.0202442
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.591673
7@#: 0.0202442
9-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.291692
7@#: 0.00597771

IG for each feature : 
0.0202442, 0, 0.198117, 0.0202442, 0.0202442, 0.00597771, 
max_IG = 0.198117 & splitOn_feature : 2
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.419973
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.419973, 0.170951, 
max_IG = 0.419973 & splitOn_feature : 4
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
4-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
8@#: 0.393156
8@#: 0.0487949
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
6-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
7-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.5
8@#: 0
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
8@#: 0.655639
8@#: 0.0487949
9-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 1
8@#: 0.75

IG for each feature : 
0.0487949, 0.137925, 0.137925, 0, 0.0487949, 0.75, 
max_IG = 0.75 & splitOn_feature : 5
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
4-#a
#b
#c
+(11)
-(11)
xxnode->totalCount = 22
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
30@#: 0.266667
30@#: 5.55112e-17
5-#a
#b
#c
+(11)
-(11)
xxnode->totalCount = 22
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
30@#: 0.266667
30@#: 5.55112e-17
6-#a
#b
#c
+(15)
-(13)
xxnode->totalCount = 28
+[label with max classified samples @ this node]
entropy += 0.482392
entropy += 0.996317
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
30@#: 0.0701046
30@#: 0.00343792
7-#a
#b
#c
+(6)
-(7)
xxnode->totalCount = 13
-[label with max classified samples @ this node]
entropy += 0.514836
entropy += 0.995727
+(8)
-(9)
xxnode->totalCount = 17
-[label with max classified samples @ this node]
entropy += 0.511747
entropy += 0.997503
32/////////////////////////////////////
## : 2
30@#: 0.568518
30@#: 0.00326666
8-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(11)
-(11)
xxnode->totalCount = 22
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
30@#: 1
30@#: 0.266667
9-#a
#b
#c
+(8)
-(8)
xxnode->totalCount = 16
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(6)
-(8)
xxnode->totalCount = 14
-[label with max classified samples @ this node]
entropy += 0.523882
entropy += 0.985228
32/////////////////////////////////////
## : 2
30@#: 0.466667
30@#: 0.00689354

IG for each feature : 
5.55112e-17, 5.55112e-17, 0.00343792, 0.00326666, 0.266667, 0.00689354, 
max_IG = 0.266667 & splitOn_feature : 4
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.419973
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.419973, 0.170951, 
max_IG = 0.419973 & splitOn_feature : 4
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.0199731, 0.170951, 
max_IG = 0.170951 & splitOn_feature : 2
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
4-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
8@#: 0.393156
8@#: 0.0487949
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
6-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
7-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.5
8@#: 0
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
8@#: 1
8@#: 0.393156
9-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.311278
8@#: 0.0612781

IG for each feature : 
0.0487949, 0.137925, 0.137925, 0, 0.393156, 0.0612781, 
max_IG = 0.393156 & splitOn_feature : 4
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
4-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
6@#: 0.459148
6@#: 0
5-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
6@#: 0
6@#: 0
6-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
6@#: 0.10917
6@#: 0.10917
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.584963
6@#: -0.0817042
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.584963
6@#: -0.0817042
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.251629
6@#: -0.0817042

IG for each feature : 
0, 0, 0.10917, -0.0817042, -0.0817042, -0.0817042, 
max_IG = 0.10917 & splitOn_feature : 2
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
4-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
7@#: 0.4138
7@#: 0.0202442
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
7@#: 0
7@#: 0
6-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
7@#: 0.198117
7@#: 0.198117
7-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.591673
7@#: 0.0202442
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.591673
7@#: 0.0202442
9-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.291692
7@#: 0.00597771

IG for each feature : 
0.0202442, 0, 0.198117, 0.0202442, 0.0202442, 0.00597771, 
max_IG = 0.198117 & splitOn_feature : 2
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
4-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
8@#: 0.393156
8@#: 0.0487949
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
6-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
7-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.5
8@#: 0
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
8@#: 0.655639
8@#: 0.0487949
9-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.311278
8@#: 0.0612781

IG for each feature : 
0.0487949, 0.137925, 0.137925, 0, 0.0487949, 0.0612781, 
max_IG = 0.137925 & splitOn_feature : 1
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
4-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
7@#: 0.4138
7@#: 0.0202442
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
7@#: 0
7@#: 0
6-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
7@#: 0.198117
7@#: 0.198117
7-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.591673
7@#: 0.0202442
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.591673
7@#: 0.0202442
9-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.291692
7@#: 0.00597771

IG for each feature : 
0.0202442, 0, 0.198117, 0.0202442, 0.0202442, 0.00597771, 
max_IG = 0.198117 & splitOn_feature : 2
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
4-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
7@#: 0.4138
7@#: 0.0202442
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
7@#: 0
7@#: 0
6-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
7@#: 0.198117
7@#: 0.198117
7-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.591673
7@#: 0.0202442
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.591673
7@#: 0.0202442
9-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.291692
7@#: 0.00597771

IG for each feature : 
0.0202442, 0, 0.198117, 0.0202442, 0.0202442, 0.00597771, 
max_IG = 0.198117 & splitOn_feature : 2
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
4-#a
#b
#c
+(6)
-(5)
xxnode->totalCount = 11
+[label with max classified samples @ this node]
entropy += 0.476983
entropy += 0.99403
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
15@#: 0.267836
15@#: 0.00116948
5-#a
#b
#c
+(5)
-(5)
xxnode->totalCount = 10
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
15@#: 0.330125
15@#: 0.00647477
6-#a
#b
#c
+(6)
-(7)
xxnode->totalCount = 13
-[label with max classified samples @ this node]
entropy += 0.514836
entropy += 0.995727
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
15@#: 0.133828
15@#: 0.000494507
7-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
15@#: 0.537019
15@#: 0.00368517
8-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(5)
-(5)
xxnode->totalCount = 10
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
15@#: 0.996792
15@#: 0.330125
9-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
15@#: 0.463458
15@#: 0.00368517

IG for each feature : 
0.00116948, 0.00647477, 0.000494507, 0.00368517, 0.330125, 0.00368517, 
max_IG = 0.330125 & splitOn_feature : 4
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 9
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 9
Harry Potter*-------------------*-*-*-*--*-*--*-*
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0, 0.311278, 
max_IG = 0.311278 & splitOn_feature : 2
$$$$: decisionTree.size(): 10
$$$$: treeLevel_node : 9
$$$$: isLeaf_else: 0
$$$$: treeLevel_else: 10
$$$$: isLeaf_if: 1
$$$$: treeLevel_if: 10
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.5
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0.5, 0.311278, 
max_IG = 0.5 & splitOn_feature : 4
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.0199731, 0.170951, 
max_IG = 0.170951 & splitOn_feature : 2
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
4-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
9@#: 0.378879
9@#: 0.0727802
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
9@#: 0.224788
9@#: 0.00256529
6-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
9@#: 0.102187
9@#: 0.102187
7-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
9@#: 0.546632
9@#: 0.00721462
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
9@#: 0.991076
9@#: 0.378879
9-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
9@#: 0.378879
9@#: 0.0727802

IG for each feature : 
0.0727802, 0.00256529, 0.102187, 0.00721462, 0.378879, 0.0727802, 
max_IG = 0.378879 & splitOn_feature : 4
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
4-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
6@#: 0.459148
6@#: 0
5-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
6@#: 0
6@#: 0
6-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
6@#: 0.10917
6@#: 0.10917
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.584963
6@#: -0.0817042
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.918296
6@#: 0.251629
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.251629
6@#: -0.0817042

IG for each feature : 
0, 0, 0.10917, -0.0817042, 0.251629, -0.0817042, 
max_IG = 0.251629 & splitOn_feature : 4
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
4-#a
#b
#c
+(6)
-(6)
xxnode->totalCount = 12
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
16@#: 0.25
16@#: 0
5-#a
#b
#c
+(6)
-(5)
xxnode->totalCount = 11
+[label with max classified samples @ this node]
entropy += 0.476983
entropy += 0.99403
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
16@#: 0.316604
16@#: 0.0131822
6-#a
#b
#c
+(6)
-(8)
xxnode->totalCount = 14
-[label with max classified samples @ this node]
entropy += 0.523882
entropy += 0.985228
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
16@#: 0.137925
16@#: 0.0129254
7-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
32/////////////////////////////////////
## : 2
16@#: 0.568963
16@#: 0.0114824
8-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(6)
-(5)
xxnode->totalCount = 11
+[label with max classified samples @ this node]
entropy += 0.476983
entropy += 0.99403
32/////////////////////////////////////
## : 2
16@#: 0.696578
16@#: 0.0131822
9-#a
#b
#c
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
16@#: 0.44252
16@#: 0.0114824

IG for each feature : 
0, 0.0131822, 0.0129254, 0.0114824, 0.0131822, 0.0114824, 
max_IG = 0.0131822 & splitOn_feature : 4
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
4-#a
#b
#c
+(5)
-(5)
xxnode->totalCount = 10
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
14@#: 0.270942
14@#: -0.0147719
5-#a
#b
#c
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
14@#: 0.348108
14@#: 0.00133974
6-#a
#b
#c
+(6)
-(6)
xxnode->totalCount = 12
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
14@#: 0.128085
14@#: -0.0147719
7-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
14@#: 0.591673
14@#: 0.0202442
8-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
32/////////////////////////////////////
## : 2
14@#: 0.985228
14@#: 0.348108
9-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
14@#: 0.492614
14@#: 0

IG for each feature : 
-0.0147719, 0.00133974, -0.0147719, 0.0202442, 0.348108, 0, 
max_IG = 0.348108 & splitOn_feature : 4
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.0199731, 0.170951, 
max_IG = 0.170951 & splitOn_feature : 2
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.0199731, 0.170951, 
max_IG = 0.170951 & splitOn_feature : 2
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.0199731, 0.170951, 
max_IG = 0.170951 & splitOn_feature : 2
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
4-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
10@#: 0.449022
10@#: 0.0490225
5-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
10@#: 0.2
10@#: -5.55112e-17
6-#a
#b
#c
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
10@#: 0.108032
10@#: 0.108032
7-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
10@#: 0.514525
10@#: 0.0290494
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
10@#: 0.724511
10@#: 0.0348516
9-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
10@#: 0.31034
10@#: 0.0348516

IG for each feature : 
0.0490225, -5.55112e-17, 0.108032, 0.0290494, 0.0348516, 0.0348516, 
max_IG = 0.108032 & splitOn_feature : 2
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
4-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
6@#: 0.459148
6@#: 0
5-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
6@#: 0
6@#: 0
6-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
6@#: 0.10917
6@#: 0.10917
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.584963
6@#: -0.0817042
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.584963
6@#: -0.0817042
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.251629
6@#: -0.0817042

IG for each feature : 
0, 0, 0.10917, -0.0817042, -0.0817042, -0.0817042, 
max_IG = 0.10917 & splitOn_feature : 2
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0, 0.311278, 
max_IG = 0.311278 & splitOn_feature : 2
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.0199731, 0.170951, 
max_IG = 0.170951 & splitOn_feature : 2
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
4-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
9@#: 0.378879
9@#: 0.0727802
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
9@#: 0.224788
9@#: 0.00256529
6-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
9@#: 0.102187
9@#: 0.102187
7-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
9@#: 0.546632
9@#: 0.00721462
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
9@#: 0.684977
9@#: 0.0727802
9-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
9@#: 0.378879
9@#: 0.0727802

IG for each feature : 
0.0727802, 0.00256529, 0.102187, 0.00721462, 0.0727802, 0.0727802, 
max_IG = 0.102187 & splitOn_feature : 2
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
4-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
6@#: 0.459148
6@#: 0
5-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
6@#: 0
6@#: 0
6-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
6@#: 0.10917
6@#: 0.10917
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.584963
6@#: -0.0817042
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.918296
6@#: 0.251629
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.251629
6@#: -0.0817042

IG for each feature : 
0, 0, 0.10917, -0.0817042, 0.251629, -0.0817042, 
max_IG = 0.251629 & splitOn_feature : 4
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0, 0.311278, 
max_IG = 0.311278 & splitOn_feature : 2
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.0199731, 0.170951, 
max_IG = 0.170951 & splitOn_feature : 2
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.5
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0.5, 0.311278, 
max_IG = 0.5 & splitOn_feature : 4
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.5
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0.5, 0.311278, 
max_IG = 0.5 & splitOn_feature : 4
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.0199731, 0.170951, 
max_IG = 0.170951 & splitOn_feature : 2
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
4-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
8@#: 0.393156
8@#: 0.0487949
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
6-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
7-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.5
8@#: 0
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
8@#: 1
8@#: 0.393156
9-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.311278
8@#: 0.0612781

IG for each feature : 
0.0487949, 0.137925, 0.137925, 0, 0.393156, 0.0612781, 
max_IG = 0.393156 & splitOn_feature : 4
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.0199731, 0.170951, 
max_IG = 0.170951 & splitOn_feature : 2
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
4-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
9@#: 0.378879
9@#: 0.0727802
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
9@#: 0.224788
9@#: 0.00256529
6-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
9@#: 0.102187
9@#: 0.102187
7-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
9@#: 0.546632
9@#: 0.00721462
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
9@#: 0.991076
9@#: 0.378879
9-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
9@#: 0.378879
9@#: 0.0727802

IG for each feature : 
0.0727802, 0.00256529, 0.102187, 0.00721462, 0.378879, 0.0727802, 
max_IG = 0.378879 & splitOn_feature : 4
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
4-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
6@#: 0.459148
6@#: 0
5-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
6@#: 0
6@#: 0
6-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
6@#: 0.10917
6@#: 0.10917
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.584963
6@#: -0.0817042
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.918296
6@#: 0.251629
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.251629
6@#: -0.0817042

IG for each feature : 
0, 0, 0.10917, -0.0817042, 0.251629, -0.0817042, 
max_IG = 0.251629 & splitOn_feature : 4
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
4-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
6@#: 0.459148
6@#: 0
5-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
6@#: 0
6@#: 0
6-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
6@#: 0.10917
6@#: 0.10917
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.584963
6@#: -0.0817042
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.918296
6@#: 0.251629
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.251629
6@#: -0.0817042

IG for each feature : 
0, 0, 0.10917, -0.0817042, 0.251629, -0.0817042, 
max_IG = 0.251629 & splitOn_feature : 4
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
4-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
8@#: 0.393156
8@#: 0.0487949
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
6-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
7-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.5
8@#: 0
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
8@#: 1
8@#: 0.393156
9-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.311278
8@#: 0.0612781

IG for each feature : 
0.0487949, 0.137925, 0.137925, 0, 0.393156, 0.0612781, 
max_IG = 0.393156 & splitOn_feature : 4
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
4-#a
#b
#c
+(8)
-(8)
xxnode->totalCount = 16
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
22@#: 0.272727
22@#: 0.022283
5-#a
#b
#c
+(7)
-(8)
xxnode->totalCount = 15
-[label with max classified samples @ this node]
entropy += 0.513117
entropy += 0.996792
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
22@#: 0.320369
22@#: 0.00688766
6-#a
#b
#c
+(11)
-(9)
xxnode->totalCount = 20
+[label with max classified samples @ this node]
entropy += 0.474373
entropy += 0.992774
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
22@#: 0.0974778
22@#: 0.00656868
7-#a
#b
#c
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
+(6)
-(7)
xxnode->totalCount = 13
-[label with max classified samples @ this node]
entropy += 0.514836
entropy += 0.995727
32/////////////////////////////////////
## : 2
22@#: 0.59456
22@#: 0.00617539
8-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(7)
-(8)
xxnode->totalCount = 15
-[label with max classified samples @ this node]
entropy += 0.513117
entropy += 0.996792
32/////////////////////////////////////
## : 2
22@#: 1
22@#: 0.320369
9-#a
#b
#c
+(6)
-(7)
xxnode->totalCount = 13
-[label with max classified samples @ this node]
entropy += 0.514836
entropy += 0.995727
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
32/////////////////////////////////////
## : 2
22@#: 0.411616
22@#: 0.00617539

IG for each feature : 
0.022283, 0.00688766, 0.00656868, 0.00617539, 0.320369, 0.00617539, 
max_IG = 0.320369 & splitOn_feature : 4
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0, 0.311278, 
max_IG = 0.311278 & splitOn_feature : 2
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.419973
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.419973, 0.170951, 
max_IG = 0.419973 & splitOn_feature : 4
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.0199731, 0.170951, 
max_IG = 0.170951 & splitOn_feature : 2
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
4-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
6@#: 0.459148
6@#: 0
5-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
6@#: 0
6@#: 0
6-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
6@#: 0.10917
6@#: 0.10917
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.584963
6@#: -0.0817042
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.584963
6@#: -0.0817042
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.251629
6@#: -0.0817042

IG for each feature : 
0, 0, 0.10917, -0.0817042, -0.0817042, -0.0817042, 
max_IG = 0.10917 & splitOn_feature : 2
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
4-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
7@#: 0.4138
7@#: 0.0202442
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
7@#: 0
7@#: 0
6-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
7@#: 0.198117
7@#: 0.198117
7-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.591673
7@#: 0.0202442
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.591673
7@#: 0.0202442
9-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.291692
7@#: 0.00597771

IG for each feature : 
0.0202442, 0, 0.198117, 0.0202442, 0.0202442, 0.00597771, 
max_IG = 0.198117 & splitOn_feature : 2
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
4-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
6@#: 0.459148
6@#: 0
5-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
6@#: 0
6@#: 0
6-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
6@#: 0.10917
6@#: 0.10917
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.584963
6@#: -0.0817042
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.918296
6@#: 0.251629
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.251629
6@#: -0.0817042

IG for each feature : 
0, 0, 0.10917, -0.0817042, 0.251629, -0.0817042, 
max_IG = 0.251629 & splitOn_feature : 4
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
4-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
6@#: 0.459148
6@#: 0
5-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
6@#: 0
6@#: 0
6-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
6@#: 0.10917
6@#: 0.10917
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.584963
6@#: -0.0817042
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.584963
6@#: -0.0817042
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.251629
6@#: -0.0817042

IG for each feature : 
0, 0, 0.10917, -0.0817042, -0.0817042, -0.0817042, 
max_IG = 0.10917 & splitOn_feature : 2
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.419973
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.419973, 0.170951, 
max_IG = 0.419973 & splitOn_feature : 4
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
4-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
10@#: 0.449022
10@#: 0.0490225
5-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
10@#: 0.2
10@#: -5.55112e-17
6-#a
#b
#c
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
10@#: 0.108032
10@#: 0.108032
7-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
10@#: 0.514525
10@#: 0.0290494
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
10@#: 1
10@#: 0.31034
9-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
10@#: 0.31034
10@#: 0.0348516

IG for each feature : 
0.0490225, -5.55112e-17, 0.108032, 0.0290494, 0.31034, 0.0348516, 
max_IG = 0.31034 & splitOn_feature : 4
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 10
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 10
Harry Potter*-------------------*-*-*-*--*-*--*-*
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 11
$$$$: treeLevel_node : 10
$$$$: isLeaf_if: 1
$$$$: treeLevel_if: 11
$$$$: isLeaf_else: 0
$$$$: treeLevel_else: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.5
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0.5, 0.311278, 
max_IG = 0.5 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.918296
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.918296, 0, 
max_IG = 0.918296 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
6@#: 0.459148
6@#: 0
5-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
6@#: 0
6@#: 0
6-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
6@#: 0.10917
6@#: 0.10917
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.584963
6@#: -0.0817042
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.918296
6@#: 0.251629
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.251629
6@#: -0.0817042

IG for each feature : 
0, 0, 0.10917, -0.0817042, 0.251629, -0.0817042, 
max_IG = 0.251629 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.5
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0.5, 0.311278, 
max_IG = 0.5 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.0199731, 0.170951, 
max_IG = 0.170951 & splitOn_feature : 2
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
11@#: 0.367067
11@#: 0.00343049
5-#a
#b
#c
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
11@#: 0.18315
11@#: 0.00133162
6-#a
#b
#c
+(5)
-(5)
xxnode->totalCount = 10
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
11@#: 0.0849393
11@#: 0.0849393
7-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
11@#: 0.493142
11@#: 0.0518004
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
11@#: 0.99403
11@#: 0.266757
9-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
11@#: 0.367067
11@#: 0.00343049

IG for each feature : 
0.00343049, 0.00133162, 0.0849393, 0.0518004, 0.266757, 0.00343049, 
max_IG = 0.266757 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.0199731, 0.170951, 
max_IG = 0.170951 & splitOn_feature : 2
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
9@#: 0.378879
9@#: 0.0727802
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
9@#: 0.224788
9@#: 0.00256529
6-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
9@#: 0.102187
9@#: 0.102187
7-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
9@#: 0.546632
9@#: 0.00721462
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
9@#: 0.684977
9@#: 0.0727802
9-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
9@#: 0.378879
9@#: 0.0727802

IG for each feature : 
0.0727802, 0.00256529, 0.102187, 0.00721462, 0.0727802, 0.0727802, 
max_IG = 0.102187 & splitOn_feature : 2
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.5
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0.5, 0.311278, 
max_IG = 0.5 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.5
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0.5, 0.311278, 
max_IG = 0.5 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.5
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0.5, 0.311278, 
max_IG = 0.5 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
4-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
9@#: 0.378879
9@#: 0.0727802
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
9@#: 0.224788
9@#: 0.00256529
6-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
9@#: 0.102187
9@#: 0.102187
7-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
9@#: 0.546632
9@#: 0.00721462
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
9@#: 0.991076
9@#: 0.378879
9-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
9@#: 0.378879
9@#: 0.0727802

IG for each feature : 
0.0727802, 0.00256529, 0.102187, 0.00721462, 0.378879, 0.0727802, 
max_IG = 0.378879 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.0199731, 0.170951, 
max_IG = 0.170951 & splitOn_feature : 2
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0, 0.311278, 
max_IG = 0.311278 & splitOn_feature : 2
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
8@#: 0.393156
8@#: 0.0487949
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
6-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
7-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.5
8@#: 0
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
8@#: 0.655639
8@#: 0.0487949
9-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.311278
8@#: 0.0612781

IG for each feature : 
0.0487949, 0.137925, 0.137925, 0, 0.0487949, 0.0612781, 
max_IG = 0.137925 & splitOn_feature : 1
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.5
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0.5, 0.311278, 
max_IG = 0.5 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0, 0.311278, 
max_IG = 0.311278 & splitOn_feature : 2
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0, 0.311278, 
max_IG = 0.311278 & splitOn_feature : 2
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.419973
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.419973, 0.170951, 
max_IG = 0.419973 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0, 0.311278, 
max_IG = 0.311278 & splitOn_feature : 2
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
4-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
6@#: 0.459148
6@#: 0
5-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
6@#: 0
6@#: 0
6-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
6@#: 0.10917
6@#: 0.10917
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.584963
6@#: -0.0817042
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.918296
6@#: 0.251629
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.251629
6@#: -0.0817042

IG for each feature : 
0, 0, 0.10917, -0.0817042, 0.251629, -0.0817042, 
max_IG = 0.251629 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0, 0.311278, 
max_IG = 0.311278 & splitOn_feature : 2
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.5
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0.5, 0.311278, 
max_IG = 0.5 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.419973
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.419973, 0.170951, 
max_IG = 0.419973 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
4-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
7@#: 0.4138
7@#: 0.0202442
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
7@#: 0
7@#: 0
6-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
7@#: 0.198117
7@#: 0.198117
7-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.591673
7@#: 0.0202442
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.985228
7@#: 0.4138
9-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.291692
7@#: 0.00597771

IG for each feature : 
0.0202442, 0, 0.198117, 0.0202442, 0.4138, 0.00597771, 
max_IG = 0.4138 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
4-#a
#b
#c
+(6)
-(5)
xxnode->totalCount = 11
+[label with max classified samples @ this node]
entropy += 0.476983
entropy += 0.99403
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
15@#: 0.267836
15@#: 0.00116948
5-#a
#b
#c
+(5)
-(5)
xxnode->totalCount = 10
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
15@#: 0.330125
15@#: 0.00647477
6-#a
#b
#c
+(6)
-(7)
xxnode->totalCount = 13
-[label with max classified samples @ this node]
entropy += 0.514836
entropy += 0.995727
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
15@#: 0.133828
15@#: 0.000494507
7-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
15@#: 0.537019
15@#: 0.00368517
8-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(5)
-(5)
xxnode->totalCount = 10
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
15@#: 0.996792
15@#: 0.330125
9-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
15@#: 0.463458
15@#: 0.00368517

IG for each feature : 
0.00116948, 0.00647477, 0.000494507, 0.00368517, 0.330125, 0.00368517, 
max_IG = 0.330125 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.918296
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.918296, 0, 
max_IG = 0.918296 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0, 0.311278, 
max_IG = 0.311278 & splitOn_feature : 2
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.0199731, 0.170951, 
max_IG = 0.170951 & splitOn_feature : 2
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
6@#: 0.459148
6@#: 0
5-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
6@#: 0
6@#: 0
6-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
6@#: 0.10917
6@#: 0.10917
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.584963
6@#: -0.0817042
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.584963
6@#: -0.0817042
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.251629
6@#: -0.0817042

IG for each feature : 
0, 0, 0.10917, -0.0817042, -0.0817042, -0.0817042, 
max_IG = 0.10917 & splitOn_feature : 2
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0, 0.311278, 
max_IG = 0.311278 & splitOn_feature : 2
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.419973
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.419973, 0.170951, 
max_IG = 0.419973 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
4-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
7@#: 0.4138
7@#: 0.0202442
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
7@#: 0
7@#: 0
6-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
7@#: 0.198117
7@#: 0.198117
7-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.591673
7@#: 0.0202442
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.591673
7@#: 0.0202442
9-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.291692
7@#: 0.00597771

IG for each feature : 
0.0202442, 0, 0.198117, 0.0202442, 0.0202442, 0.00597771, 
max_IG = 0.198117 & splitOn_feature : 2
$$$$: decisionTree.size(): 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 11
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 11
Harry Potter*-------------------*-*-*-*--*-*--*-*
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 12
$$$$: treeLevel_node : 11
$$$$: isLeaf_if: 1
$$$$: treeLevel_if: 12
$$$$: isLeaf_if: 1
$$$$: treeLevel_if: 12
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.5
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0.5, 0.311278, 
max_IG = 0.5 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 12
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.5
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0.5, 0.311278, 
max_IG = 0.5 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 12
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 12
4-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
8@#: 0.393156
8@#: 0.0487949
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
6-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
7-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.5
8@#: 0
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
8@#: 1
8@#: 0.393156
9-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.311278
8@#: 0.0612781

IG for each feature : 
0.0487949, 0.137925, 0.137925, 0, 0.393156, 0.0612781, 
max_IG = 0.393156 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 12
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.5
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0.5, 0.311278, 
max_IG = 0.5 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 12
4-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
8@#: 0.393156
8@#: 0.0487949
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
6-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
8@#: 0.137925
8@#: 0.137925
7-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.5
8@#: 0
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
8@#: 0.655639
8@#: 0.0487949
9-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
8@#: 0.311278
8@#: 0.0612781

IG for each feature : 
0.0487949, 0.137925, 0.137925, 0, 0.0487949, 0.0612781, 
max_IG = 0.137925 & splitOn_feature : 1
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 12
4-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
6@#: 0.459148
6@#: 0
5-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
6@#: 0
6@#: 0
6-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
6@#: 0.10917
6@#: 0.10917
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.584963
6@#: -0.0817042
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.584963
6@#: -0.0817042
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.251629
6@#: -0.0817042

IG for each feature : 
0, 0, 0.10917, -0.0817042, -0.0817042, -0.0817042, 
max_IG = 0.10917 & splitOn_feature : 2
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0, 0.311278, 
max_IG = 0.311278 & splitOn_feature : 2
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 12
4-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
7@#: 0.4138
7@#: 0.0202442
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
7@#: 0
7@#: 0
6-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
7@#: 0.198117
7@#: 0.198117
7-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.591673
7@#: 0.0202442
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.985228
7@#: 0.4138
9-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.291692
7@#: 0.00597771

IG for each feature : 
0.0202442, 0, 0.198117, 0.0202442, 0.4138, 0.00597771, 
max_IG = 0.4138 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 12
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.918296
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.918296, 0, 
max_IG = 0.918296 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 12
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.918296
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.918296, 0, 
max_IG = 0.918296 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 12
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.5
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0.5, 0.311278, 
max_IG = 0.5 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 12
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 12
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 12
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 12
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0, 0.311278, 
max_IG = 0.311278 & splitOn_feature : 2
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.0199731, 0.170951, 
max_IG = 0.170951 & splitOn_feature : 2
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
4-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
10@#: 0.449022
10@#: 0.0490225
5-#a
#b
#c
+(4)
-(4)
xxnode->totalCount = 8
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
10@#: 0.2
10@#: -5.55112e-17
6-#a
#b
#c
+(4)
-(5)
xxnode->totalCount = 9
-[label with max classified samples @ this node]
entropy += 0.519967
entropy += 0.991076
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
10@#: 0.108032
10@#: 0.108032
7-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
10@#: 0.514525
10@#: 0.0290494
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
10@#: 1
10@#: 0.31034
9-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
10@#: 0.31034
10@#: 0.0348516

IG for each feature : 
0.0490225, -5.55112e-17, 0.108032, 0.0290494, 0.31034, 0.0348516, 
max_IG = 0.31034 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 12
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 12
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.5
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0.5, 0.311278, 
max_IG = 0.5 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 12
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.0199731, 0.170951, 
max_IG = 0.170951 & splitOn_feature : 2
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.918296
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.918296, 0, 
max_IG = 0.918296 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 12
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 12
4-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
6@#: 0.459148
6@#: 0
5-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
32/////////////////////////////////////
## : 2
6@#: 0
6@#: 0
6-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
6@#: 0.10917
6@#: 0.10917
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.584963
6@#: -0.0817042
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.918296
6@#: 0.251629
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
6@#: 0.251629
6@#: -0.0817042

IG for each feature : 
0, 0, 0.10917, -0.0817042, 0.251629, -0.0817042, 
max_IG = 0.251629 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 12
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 12
Harry Potter*-------------------*-*-*-*--*-*--*-*
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 13
$$$$: treeLevel_node : 12
$$$$: isLeaf_if: 1
$$$$: treeLevel_if: 13
$$$$: isLeaf_if: 1
$$$$: treeLevel_if: 13
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 14
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 14
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 14
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 14
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.918296
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.918296, 0, 
max_IG = 0.918296 & splitOn_feature : 4
$$$$: decisionTree.size(): 14
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.0199731, 0.170951, 
max_IG = 0.170951 & splitOn_feature : 2
$$$$: decisionTree.size(): 14
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 14
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 14
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
4-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
7@#: 0.4138
7@#: 0.0202442
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
7@#: 0
7@#: 0
6-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
7@#: 0.198117
7@#: 0.198117
7-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.591673
7@#: 0.0202442
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.985228
7@#: 0.4138
9-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.291692
7@#: 0.00597771

IG for each feature : 
0.0202442, 0, 0.198117, 0.0202442, 0.4138, 0.00597771, 
max_IG = 0.4138 & splitOn_feature : 4
$$$$: decisionTree.size(): 14
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 13
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 13
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 14
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.570951
5@#: 0.0199731
5-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
32/////////////////////////////////////
## : 2
5@#: 0
5@#: 0
6-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.170951
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
5@#: 0.970951
5@#: 0.419973
9-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
5@#: 0.170951
5@#: 0.170951

IG for each feature : 
0.0199731, 0, 0.170951, 0.170951, 0.419973, 0.170951, 
max_IG = 0.419973 & splitOn_feature : 4
$$$$: decisionTree.size(): 14
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 13
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 13
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 14
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 13
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 14
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 14
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 13
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0, 0.311278, 
max_IG = 0.311278 & splitOn_feature : 2
$$$$: decisionTree.size(): 14
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 14
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 14
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 14
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 14
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 14
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 14
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 14
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 14
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 14
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 14
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 13
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0, 0.311278, 
max_IG = 0.311278 & splitOn_feature : 2
$$$$: decisionTree.size(): 14
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 14
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 13
4-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
7@#: 0.4138
7@#: 0.0202442
5-#a
#b
#c
+(4)
-(3)
xxnode->totalCount = 7
+[label with max classified samples @ this node]
entropy += 0.461346
entropy += 0.985228
32/////////////////////////////////////
## : 2
7@#: 0
7@#: 0
6-#a
#b
#c
+(4)
-(2)
xxnode->totalCount = 6
+[label with max classified samples @ this node]
entropy += 0.389975
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
7@#: 0.198117
7@#: 0.198117
7-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.591673
7@#: 0.0202442
8-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.985228
7@#: 0.4138
9-#a
#b
#c
+(3)
-(2)
xxnode->totalCount = 5
+[label with max classified samples @ this node]
entropy += 0.442179
entropy += 0.970951
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
7@#: 0.291692
7@#: 0.00597771

IG for each feature : 
0.0202442, 0, 0.198117, 0.0202442, 0.4138, 0.00597771, 
max_IG = 0.4138 & splitOn_feature : 4
$$$$: decisionTree.size(): 14
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 13
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 13
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 14
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 14
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 14
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.5
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0.5, 0.311278, 
max_IG = 0.5 & splitOn_feature : 4
$$$$: decisionTree.size(): 14
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 13
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 13
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 14
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 14
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 14
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 13
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.5
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0.5, 0.311278, 
max_IG = 0.5 & splitOn_feature : 4
$$$$: decisionTree.size(): 14
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 13
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 13
Harry Potter*-------------------*-*-*-*--*-*--*-*
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 14
$$$$: treeLevel_node : 13
$$$$: isLeaf_if: 1
$$$$: treeLevel_if: 14
$$$$: isLeaf_if: 1
$$$$: treeLevel_if: 14
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.5
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0.5, 0.311278, 
max_IG = 0.5 & splitOn_feature : 4
$$$$: decisionTree.size(): 15
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 14
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 14
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 15
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 14
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 14
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0, 0.311278, 
max_IG = 0.311278 & splitOn_feature : 2
$$$$: decisionTree.size(): 15
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 14
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 14
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 15
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 14
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 14
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 15
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 14
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 14
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 15
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 14
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 14
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 15
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 14
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 14
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 15
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 14
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 14
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 15
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 14
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 14
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.918296
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.918296, 0, 
max_IG = 0.918296 & splitOn_feature : 4
$$$$: decisionTree.size(): 15
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 14
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 14
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 15
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 14
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 14
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 15
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 14
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 14
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
5-#a
#b
#c
+(2)
-(2)
xxnode->totalCount = 4
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0
4@#: 0
6-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
4@#: 1
4@#: 0.311278
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
4@#: 0.5
4@#: 0
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
4@#: 0.311278
4@#: 0.311278

IG for each feature : 
0, 0, 0.311278, 0.311278, 0, 0.311278, 
max_IG = 0.311278 & splitOn_feature : 2
$$$$: decisionTree.size(): 15
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 14
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 14
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 15
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 14
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 14
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 15
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 14
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 14
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 15
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 14
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 14
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 15
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 14
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 14
Harry Potter*-------------------*-*-*-*--*-*--*-*
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 15
$$$$: treeLevel_node : 14
$$$$: isLeaf_if: 1
$$$$: treeLevel_if: 15
$$$$: isLeaf_if: 1
$$$$: treeLevel_if: 15
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 16
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 15
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 15
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 16
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 15
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 15
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.918296
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.918296, 0, 
max_IG = 0.918296 & splitOn_feature : 4
$$$$: decisionTree.size(): 16
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 15
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 15
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 16
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 15
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 15
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 16
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 15
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 15
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 16
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 15
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 15
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 16
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 15
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 15
4-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
5-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
7-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
3@#: 0.918296
3@#: 0.251629
8-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
3@#: 0.251629
3@#: 0.251629
9-#a
#b
#c
+(1)
-(2)
xxnode->totalCount = 3
-[label with max classified samples @ this node]
entropy += 0.528321
entropy += 0.918296
32/////////////////////////////////////
## : 2
3@#: 0
3@#: 0

IG for each feature : 
0.251629, 0, 0.251629, 0.251629, 0.251629, 0, 
max_IG = 0.251629 & splitOn_feature : 0
$$$$: decisionTree.size(): 16
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 15
$$$$: isLeaf_elseif_else: 0
$$$$: treeLevel_elseif_else: 15
Harry Potter*-------------------*-*-*-*--*-*--*-*
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 16
$$$$: treeLevel_node : 15
$$$$: isLeaf_if: 1
$$$$: treeLevel_if: 16
$$$$: isLeaf_if: 1
$$$$: treeLevel_if: 16
4-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
5-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
6-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0
7-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 0
8-#a
#b
#c
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
+(1)
xxnode->totalCount = 1
+[label with max classified samples @ this node]
entropy += 0
32/////////////////////////////////////
## : 2
2@#: 1
2@#: 1
9-#a
#b
#c
+(1)
-(1)
xxnode->totalCount = 2
+[label with max classified samples @ this node]
entropy += 0.5
entropy += 1
32/////////////////////////////////////
## : 2
2@#: 0
2@#: 0

IG for each feature : 
0, 0, 0, 0, 1, 0, 
max_IG = 1 & splitOn_feature : 4
$$$$: decisionTree.size(): 17
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 16
$$$$: isLeaf_elseif_if: 1
$$$$: treeLevel_elseif_if: 16
Harry Potter*-------------------*-*-*-*--*-*--*-*
xxxxxxxxxxxxxxDT.size() = 17
after
xxxxxxxxxxxxxxDT.size() = 17
