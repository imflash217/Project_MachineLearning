<!-- page_number: true -->
<!-- $height: 9in -->
<!-- $width: 13in -->
	
				MACHINE LEARNING
				     Notes
                             

<!-- footer: Built w/ Marp ~ 2017 ~ by @vinaykumar2491 -->

-------------------------------------------------------------------------------------
### Supervised Learning:
	Applications in which the training data comprises of input vectors 
    along with the corresponding target vectors.
    
### Classification:
	Applications in which the aim is to assign the input vector to one of 
    a finite numer of discrete categories.
    
    For ex: Classification of digits in digit-recognition prolem.
### Regression:
	Similar to Classification problem, but if the desired output consists 
    of one or more continuous variables then the task is called Regression
    
    For ex: If the desired o/p is 'yield' of a chemical manufacturing 
    plant where the input vector is temperature, pressure, 
    conc. of reactants etc.
    
-------------------------------------------------------------------------------------
### Unsupervised Learning:
	In other pattern recognition problems, the trainig data consists 
    of a set of input vectors X without any corresponding target vectors.
    This is called Unsupervised Learning problem.
    
### Clustering:
	Unsupervised learning problems where the goal is to discover groups 
    of similar examples within the data.
    
### Density Estimation:
	Unsupervised learning problem where the goal is to determine the 
    distribution of data within the input space.

-------------------------------------------------------------------------------------
### Reinforcement Learning:
       
       It is concerned with the problem of finding a suitable actions
       to take in a given situation to maximize a reward.
       --------------------------------------------------------------
       
       Here the learning algorithm is not given the examples of optimal
       output, in contrast to Supervised Learning, but must instead 
       discover them by Trial & Error.
       
       Typically there is a sequence of states & actions in which the
       learning algorithm is interacting with its environment.
       
       In many cases, the current action not only affects the immediate 
       reward but also has an impact on the rewards at all subsequent time
       steps.
       
       For eg: Using appropriate reinforcement learning techniques a 
       Neural Network can learn to play a game of chessboard to a very 
       high standard.
       
       A general feature of reinforcement learning is a trade-off b/w
       1. EXPLORATION: System tries out new kinds of actions to know how
       		   effective they are
       2. EXPLOITATION: System uses known actions to yield a high reward
       
       

-------------------------------------------------------------------------------------  
### Linear Models:
	Functions which are linear in unknown parameters are known as 
    Linear Models.
    
    .
-------------------------------------------------------------------------------------